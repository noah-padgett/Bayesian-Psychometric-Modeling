--- 
title: "Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy"
author: "R. Noah Padgett"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::bs4_book
self_contained: true
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: noah-padgett/Bayesian-Psychometric-Modeling
description: "This online book is meant to serve a computation reference for the text Bayesian Psychometric Modeling by Roy Levy and Robert Mislevy. We hope that having a detailed computatin guide using Stan is of interest to someone."
---
--- 
title: "Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy"
author: "R. Noah Padgett"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::bs4_book
self_contained: true
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: noah-padgett/Bayesian-Psychometric-Modeling
description: "This online book is meant to serve a computation reference for the text Bayesian Psychometric Modeling by Roy Levy and Robert Mislevy. We hope that having a detailed computatin guide using Stan is of interest to someone."
---
```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```

```{r init-setup, echo=F, warning=F, error=F, message=F}

knitr::opts_chunk$set(
    cache = TRUE,
    R.options=list(width=100),
    out.width = "90%", 
    out.height = "90%"
)

```


# (PART) Foundations {-}

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:index.Rmd-->


# Overview 

Placeholder


## Software 
## Overview of Assessment and Psychometric Modeling
## Looking Forward

<!--chapter:end:01-overview.Rmd-->


# Introduction to Bayesian Inference {#chp2}

Placeholder


## Beta-binomial Example
### Computation using Stan
### Computation using WinBUGS (OpenBUGS)
### Computation using JAGS (R2jags)
## Beta-Bernoulli Example
### Computation using Stan
### Computation using WinBUGS (OpenBUGS)
### Computation using JAGS (R2jags)

<!--chapter:end:02-intro-bayes.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
# Conceptual Issues in Bayesian Inference

This chapter was conceptual so there was no code.
```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:03-conceptual-issues.Rmd-->


# Normal Distribution Models

Placeholder


## Stan Model for mean and variance unknown
## JAGS Model for mean and variance unknown (precision parameterization)

<!--chapter:end:04-normal-models.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
# Markov Chain Monte Carlo Estimation

This chapter on MCMC methods gives an introduction to some of the common and basic sampling approaches for Bayesian methods.
These methods in

1. Gibbs Sampling

2. Metropolis Sampling

3. Metropolis-Hastings

and some notes on how these approaches are related.
The most important take away for me was their section on practical issues in MCMC methods.
These practical aspects of estimation that should be noted are:

1. Assessing convergence - making sure enough iterations have been used including the potential scale reduction factor ($\hat{R}$),

2. Serial dependence - where the samples drawn from the posterior are autocorrelated. This means that within a chain the draws are dependent but with enough draws and thinning all samples are sufficiently independent,

3. Mixing - that different chains search/sample from the same parameter space but different chains can sometimes get "stuck" sampling one part of the parameter space that is not the same as the other chains.

Lastly, a major take away from this chapter is that MCMC methods help to approximate the posterior distribution.
The *distribution* is the solution of a full Bayesian analysis and not a point estimate.

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:05-mcmc.Rmd-->


# Regression

Placeholder


## Stan Model for Regression Model
## JAGS Model for Regression Model

<!--chapter:end:06-regression.Rmd-->


# (PART) Psychometrics {-}
# Canonical Bayesian Psychometric Modeling

Placeholder



<!--chapter:end:07-canonical-bpm.Rmd-->


# Classical Test Theory

Placeholder


## Example 1 - Known measurement model parameters with 1 measure
## Example 1 - Stan
## Example 1 - JAGS
## Example 2 - Known Measurement Model with Multiple Measures
## Example 2 - Stan
## Example 2 - JAGS
## Example 3 - Unknown Measurement Model with Multiple Measures
## Example 3 - Stan
## Example 3 - JAGS

<!--chapter:end:08-ctt.Rmd-->


# Confirmatory Factor Analysis

Placeholder


## Single Latent Variable Model
## JAGS - Single Latent Variable
## Stan - Single Latent Variable 
## Blavaan - Single Latent Variable
## Two Latent Variable Model
## JAGS - Two Latent Variable
## Stan - Two Latent Variable 
### Inverse-Wishart Prior
### LKJ Cholesky Parameterization
## Blavaan - Two Latent Variables
## Indeterminacy in One Factor CFA

<!--chapter:end:09-cfa.Rmd-->


# Model Evaluation

Placeholder


## Residual Analysis
## Posterior Predictive Distributions
### Example of posterior predictive distribution of correlations
### PPD SRMR
## Model Comparison

<!--chapter:end:10-model-evaluation.Rmd-->


# Item Response Theory

Placeholder


## IRT Models for Dichotomous Data
## 3-PL LSAT Example
## LSAT Example - JAGS
### Posterior Predicted Distributions
## LSAT Example - Stan
## IRT Models for Polytomous Data
## GRM Peer Interactions Example
### Example Specific Model Specification
## PI Example - JAGS
## PI Example - Stan
## Latent Response Formulation
### LSAT Example Revisted
## Final Notes

<!--chapter:end:11-irt.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
# Missing Data Modeling


TO-DO

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:12-missing-data.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
# Latent Class Analysis

Latent class analysis (LCA) takes a different approach to modeling latent variables than has been discussed in the previous chapters (especially CFA or IRT).
The major distinguishing aspect of LCA is that the latent variable is hypothesized to be a discrete random variable as opposed to a continuous random variable.
This shift in perspective is beneficial to researchers/analysts wishing to think categorically and discuss groups of observations/people/units as opposed to a dimension of possible differences.

LCA is often used in an exploratory nature to try to identify the number of "latent classes" or unobserved groups.
However, in the text, Levy and Mislevy discuss what they describe as a more "confirmatory" approach to LCA.
The major distinction is that they specify the number of classes to be known, and treat this chapter as a resource for how to estimate the model within a Bayesian framework.

To extend their work, we have added a section on model selection and provided resources for the interested reader.
But, in general, the topic of model selection in Bayesian LCA (and Bayesian SEM more generally) is still an ongoing area of research.
Many views exist on how to conduct model selection (if at all) and we will try to present an array of options that have been proposed.

## LCA Model Specification

LCA is a _finite mixture model_.
A mixture model is generally any statistical model that combines distributions to describe different subsets or aspects of the data.
For example, LCA is a mixture model that posits class specific item/indicator response probabilities.
Different classes have a different distribution or expected response on average.
Each unit of observation (e.g., person) is assumed to belong to 1 and only 1 class.
Because individuals can only belong to one class, the different classes of observations make up different subsets of the data used in the analysis.
One result of an LCA model is the ability to identify the likelihood that an individual belongs to a particular class which is sometimes called probabilistic clustering.


Let $x_{ij}$ be the observed value from respondent $i=1, \ldots, N$ on observable (item) $j=1, \ldots, J$.
Because $x$ is binary, the observed value can be $0$ or $1$. 
The latent class variable commonly denoted with a $C$ to represent the total number of latent classes.
Let $\theta_i$ represent the class for individual $i$, where $\theta_i \in \lbrace 1, \ldots, C\rbrace$.
Similar to IRT, LCA models the probability of the observed response.
However, LCA we estimate this value more directly because the value only depends on latent class membership instead of the value being indirectly estimated through item difficulties and discrimination parameters.
The model for the observed response being 1 is
\[p(x_{ij} = 1) = \sum_{c=1}^Cp(x_{ij}=1\mid\theta_i=c,\pi_j)\gamma_c,\]
where,

* $p(x_{ij}=1\mid\theta_i=c,\pi_i)$ is class specific conditional response probability to item $i$,
* $\pi_j$ represents the item parameters, in this case it is simply the conditional probability, but can be expanded to be a set of item parameters (e.g., IRT-like),
* $\gamma_c$ represents the class _mixing weight_ or the class size parameter. The size of each class helps to identify how likely an individual in to be in any of the $C$ classes if we had no other information.
* Additionally, the class mixing weights always sums to $1$, that is

\[\sum_{c=1}^C\gamma_c = \sum_{c=1}^Cp(\theta_i=c) = 1.\]

Another way of interpreting the mixing weight is as a class proportion.
This framing can sometimes make it easier to see that the indicator response probability is a weighted average of response probabilities over the $C$ classes. 
The larger the class the more that class influences the expected response probabilities.

### LCA Model Indeterminacy

One common aspect of LCA than can be a bit of a headache at times if not carefully considered is an issue known as label switching.
LCA models discrete latent variables which do not have any inherent labels, as CFA/IRT model continuous latent variables that do not have any inherent scale/metric.

### Model Likelihood

The likelihood function for LCA follows a similar development as the likelihood function from CFA and IRT.
We assume that the individuals are independent ($i$'s are exchangeable).
We assume that the responses to each item are conditionally (locally) independent ($j$'s are exchangeable).
The joint probability conditional on the latent variable $C$ is

\[p(\mathbf{x}_i \vert \mathbf{\theta}, \mathbf{\pi}) = \prod_{i=1}^Np(\mathbf{x}_i \vert \theta_i=c, \mathbf{\pi}) = \prod_{i=1}^N\prod_{j=1}^Jp(x_{ij} \vert \theta_i=c, \pi_j).\]

The marginal probability when the observed data when we sum over the possible latent classes becomes

\[\begin{align*}
p(\mathbf{x}_i \vert \mathbf{\pi}, \mathbf{\gamma}) &= \prod_{i=1}^N\sum_{c=1}^C p(\mathbf{x}_i \vert \theta_i=c, \mathbf{\pi})p(\theta_i = c \vert \gamma)\\
&= \prod_{i=1}^N\left(\sum_{c=1}^C \left(\prod_{j=1}^J p(x_{ij} \vert \theta_i=c, \pi_j)\right)p(\theta_i = c \vert \gamma)\right)
\end{align*}
\]

## Bayesian LCA Model Specification

For the Bayesian formulation of the LCA model, the construction will be carried out in pieces similar to previous chapters.

```{r chp13-dag-1, echo=FALSE,fig.align='center',fig.cap='DAG for a general latent class analysis model', out.width="50%"}
knitr::include_graphics(paste0(w.d,'/dag/chp13-lca1.png'),
                        auto_pdf = TRUE)
```

### Distribution of Observed Indicators

First, the distribution of the observed variables is specified as a product of independent probabilities.
That is, the observed data distribution is _categorical(.)_.
Or

\[\begin{align*}
p(\mathbf{x}\vert \mathbf{\theta}, \mathbf{\pi})&= \prod_{i=1}^N p(\mathbf{x}_i\vert \theta_i, \mathbf{\pi}) = \prod_{i=1}^N \prod_{j=1}^J p(x_{ij}\vert \theta_i, \mathbf{\pi}_j),\\
x_{ij} &\sim \mathrm{Categorical}(\pi_{cj})\\
\end{align*}\]
where the model holds for observables taking values coded as $1,...,K$ with the categorical indicators.
One of the major changes from an IRT model is that the latent variables are categorical, resulting in a different distribution for the latent variable.
The _Dirichlet_ distribution is commonly used as the prior for the categorical latent variables.
The Dirichlet distribution is a generalization of the Beta distribution to more than two district outcomes.
The distribution models the categorical data as the likelihood or propensity to be one of the categoricals.

### Prior Distributions

The LCA model, as described here, contains two major types of parameters. 
That is, (1) the latent class status for each respondent and (2) the class specific category proportions.
These two parameter types are vectors over respondents and items, respectively.
The joint prior distribution can be generally described as
\[p(\theta, \pi) = p(\theta)p(\pi),\]
due to assuming independence between these two types of parameters.
Independence is a logical assumption and aligns with the IRT and CFA traditions that latent variable values are independent of the measurement model parameters.

The prior for the latent variables is represents the prior for the discrete groups respondents are assumed to belong to.
A common prior is placed over all respondents
\[p(\theta)=\prod_{i=1}^np(\theta_i\vert\mathbf{\theta}_p),\]
where $\mathbf\theta_p$ represents the hyperpriors defining the conditions of the categorical latent variables.
The vector of parameters $\mathbf\theta_p = \mathbf\gamma = (\gamma_1, \gamma_2, ..., \gamma_C)$, where $C$ is the number of latent groups.
Stated in another way,
\[\theta_i | \mathbf\gamma \sim \mathrm{Categorical}(\mathbf\gamma).\]

The hyperprior for the categorical latent variable is also commonly given a prior distribution.
The $\mathbf\gamma$ parameters represent the class proportions and a prior on these parameters is useful when these class proportions are not known.
The prior is
\[\mathbf\gamma \sim \mathrm{Dirichlet}(\mathbf\alpha_\gamma),\]
where $\mathbf\alpha_\gamma = (\alpha_{\gamma 1}, \alpha_{\gamma 2}, ..., \alpha_{\gamma C}).$
The Dirichlet distribution is a generalization of the Beta distribution to more than two categories.
This allows for a useful representation of the probabilities with well known statistical and sampling properties.

The priors for the measurement model parameters ($\mathbf\pi$) are commonly defined at the item level instead of jointly over all items:
\[p(\mathbf\pi) = \prod_{j=1}^Jp(\mathbf\pi_j\vert\mathbf\alpha_\pi),\]
where $\mathbf\alpha_\pi$ defines the hyperpriors for the measurement model parameters.
The measurement model commonly utilizes either dichotomous or categorical indicators which leads to the use of either the Beta distribution or Dirichlet distribution for the priors.

### Full Model Specification

The full model specification can be shown as follows:

\[
\begin{align*}
p(\mathbf\theta, \mathbf\gamma, \mathbf\pi) &\propto p(\mathbf{x} \vert \mathbf\theta, \mathbf\gamma, \mathbf\pi) p(\mathbf\theta, \mathbf\gamma, \mathbf\pi)\\
 &= p(\mathbf{x} \vert \mathbf\theta, \mathbf\gamma, \mathbf\pi) p(\mathbf\theta) p(\mathbf\gamma) p(\mathbf\pi)\\
 &= \prod_{i=1}^N \prod_{j=1}^J p(x_{ij}\vert \theta_i, \mathbf{\pi}_j)p(\theta_i \vert \mathbf\gamma)p(\mathbf\gamma) \prod_{c=1}^Cp(\mathbf\pi_{cj})
\end{align*}
\]

## Extending LCA

In LCA, the mixing of distributions can be generalized to include more complex components such as factor models to model the response process within class.
For example, we can have factor mixture models where different CFA models hold for different subsets of the population.

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:13-lca.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
# Bayesian Networks

TO-DO

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:14-bayes-networks.Rmd-->

```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: load_packages.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2020-09-01
# Date Modified: 2020-09-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for loading all necessary
#   R packages
#
# No output - just loading packages into the
#   environment
# ============================================= #
# Set up directory and libraries
# rm(list=ls())
# list of packages
packages <- c("patchwork", "tidyr", "dplyr",
              "dtplyr", "data.table", "ggplot2",
              "R2jags","R2WinBUGS", "blavaan",
              "rstan", "brms", "bayesplot", "ggmcmc",
              "kableExtra", "extraDistr",
              "dagitty", "ggdag", "ggraph", "cowplot",
              "pdftools")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Load packages
lapply(packages, library, character.only = TRUE)

w.d <- getwd()

# pdf to png

library(pdftools)
w.d <- getwd()

files.all <- list.files(paste0(w.d, '/dag/'))

files <- paste0(paste0(w.d, '/dag/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# model specification diagrams
files.all <- list.files(paste0(w.d, '/model-spec/'))

files <- paste0(paste0(w.d, '/model-spec/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}



# path diagrams
files.all <- list.files(paste0(w.d, '/path-diagram/'))

files <- paste0(paste0(w.d, '/path-diagram/'), grep(".pdf", files.all, value=T))
files.out <- paste0(unlist(strsplit(files, ".pdf")), ".png")
dpi <- rep(400,length(files))
for(i in 1:length(files)){
  pdf_convert(files[i], format = "png", dpi = dpi[i],
              filenames = files.out[i])
}

# Useful R functions for ploting and inspecting results

# for Stan, extract results and compute Gelman-Rubin-Brooks convergence plot
plot_rhat <- function(fit, par){
  dat <- as.array(fit)
  dim.dat <- dim(dat)
  rhat_est <- data.frame(matrix(nrow=dim.dat[1], ncol=dim.dat[3]+1))
  colnames(rhat_est) <- c('iter', dimnames(dat)[['parameters']])
  rhat_est$iter <- 1:dim.dat[1]

  pdat <- dat[,, parameters=par]

  for(i in 1:dim.dat[1]){
    rhat_est[i, par] <- rstan::Rhat(pdat[1:i,])
  }

  rhat_est$PARA <- rhat_est[, par]

  a<-ggplot(rhat_est, aes(x=iter, y=PARA)) +
    geom_line()+
    geom_hline(yintercept = 1, linetype="dashed", color="grey")+
    lims(y=c(min(rhat_est[,par])-0.05, max(rhat_est[,par])+0.05)) +
    labs(y="Rhat",
         x="Post-warm-up iteration",
         title=paste0("Iteration Evolution of Gelman-Rubin-Brooks Convergence Criterion: ", par),
         subtitle = "Should approach 1 as iterations increase") +
    theme_bw() +
    theme(panel.grid = element_blank())
  return(a)
}
```
`r if (knitr:::is_html_output()) '
# References {-}
'`
```{r include=FALSE, cache=FALSE}
# ============================================= #
# script: clean_workspace.R
# Project: Code Guide BPM
# Author(s): R.N. Padgett
# ============================================= #
# Data Created: 2021-04-04
# Date Modified: 2021-04-04
# By: R. Noah Padgett
# ============================================= #
# Stems from Padgett's Independent Study
# ============================================= #
# Purpose:
# This R script is for clearing the workspace
#   Helps to reduce lag after running
#
# No output - cleans workspace
# ============================================= #

rm(list=ls())
```

<!--chapter:end:99-references.Rmd-->

