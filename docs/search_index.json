[
["regression.html", "Chapter 6 Regression", " Chapter 6 Regression For the regression models, we have built up what the DAG could look like. These representations are shown below. Figure 6.1: DAG a simple regression model with 1 predictor Figure 6.2: DAG for a regression with \\(J\\) predictors Figure 6.3: Expanded DAG representation for regression with hyperparameters included Next, we gave a general representation of how the model specification diagram could be constructed. Figure 6.4: Model specification diagram for a linear regression model "],
["stan-model-for-regression-model.html", "6.1 Stan Model for Regression Model", " 6.1 Stan Model for Regression Model model_reg &lt;- &#39; data { int N; real x1[N]; real x2[N]; real y[N]; } parameters { real beta[3]; real&lt;lower=0&gt; tau; } transformed parameters { real&lt;lower=0&gt; sigma; sigma = 1/sqrt(tau); } model { for(i in 1:N){ y[i] ~ normal(beta[1] + beta[2]*x1[i] + beta[3]*x2[i], sigma); } beta ~ normal(0, 100); tau ~ gamma(1, 1); } generated quantities { real varerror; real vary; real Rsquared; real error[N]; for(i in 1:N){ error[i] = y[i] - (beta[1] + beta[2]*x1[i] + beta[3]*x2[i]); } varerror = variance(error); vary = variance(y); Rsquared = 1 - (varerror/vary); } &#39; # data must be in a list dat &lt;- read.table(&quot;data/Chp4_Reg_Chapter_Tests.dat&quot;, header=T) mydata &lt;- list( N=nrow(dat), x1=dat$Ch1Test, x2=dat$Ch2Test, y =dat$Ch3Test ) # start values start_values &lt;- function(){ list(sigma=1, beta=c(0,0,0)) } # Next, need to fit the model # I have explicited outlined some common parameters fit &lt;- stan( model_code = model_reg, # model code to be compiled data = mydata, # my data init = start_values, # starting values chains = 4, # number of Markov chains warmup = 1000, # number of warm up iterations per chain iter = 5000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) refresh = 0 # no progress shown ) ## Warning in system(paste(CXX, ARGS), ignore.stdout = TRUE, ignore.stderr = TRUE): &#39;-E&#39; not ## found # first get a basic breakdown of the posteriors print(fit) ## Inference for Stan model: 66db47b16bda4d720cafb6a9769da243. ## 4 chains, each with iter=5000; warmup=1000; thin=1; ## post-warmup draws per chain=4000, total post-warmup draws=16000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## beta[1] -2.53 0.02 1.92 -6.31 -3.79 -2.51 -1.26 1.23 6902 1 ## beta[2] 0.66 0.00 0.17 0.33 0.55 0.66 0.77 0.99 6171 1 ## beta[3] 0.38 0.00 0.10 0.18 0.31 0.38 0.45 0.59 8164 1 ## tau 0.28 0.00 0.06 0.18 0.24 0.28 0.32 0.41 8776 1 ## sigma 1.91 0.00 0.20 1.57 1.77 1.89 2.03 2.36 8279 1 ## varerror 3.66 0.00 0.16 3.51 3.54 3.61 3.71 4.09 4951 1 ## vary 8.79 0.00 0.00 8.79 8.79 8.79 8.79 8.79 2 1 ## Rsquared 0.58 0.00 0.02 0.53 0.58 0.59 0.60 0.60 4951 1 ## error[1] -0.25 0.02 1.40 -2.97 -1.16 -0.26 0.66 2.52 7141 1 ## error[2] 1.72 0.01 0.50 0.74 1.38 1.72 2.04 2.70 7445 1 ## error[3] -1.05 0.01 0.56 -2.15 -1.43 -1.05 -0.67 0.05 6866 1 ## error[4] -3.20 0.01 0.76 -4.70 -3.70 -3.20 -2.68 -1.72 6827 1 ## error[5] -2.80 0.01 0.52 -3.82 -3.14 -2.80 -2.45 -1.76 9994 1 ## error[6] 0.44 0.00 0.41 -0.37 0.17 0.44 0.72 1.26 9692 1 ## error[7] -1.94 0.00 0.39 -2.71 -2.20 -1.94 -1.68 -1.16 9036 1 ## error[8] -6.22 0.00 0.39 -6.98 -6.47 -6.22 -5.96 -5.45 11261 1 ## error[9] 3.40 0.00 0.34 2.74 3.18 3.40 3.63 4.07 11991 1 ## error[10] 4.02 0.00 0.31 3.41 3.81 4.02 4.23 4.63 11859 1 ## error[11] -0.75 0.00 0.35 -1.44 -0.98 -0.74 -0.51 -0.05 9382 1 ## error[12] 0.49 0.01 0.49 -0.47 0.16 0.49 0.82 1.44 8248 1 ## error[13] 2.49 0.01 0.49 1.53 2.16 2.49 2.82 3.44 8248 1 ## error[14] -0.73 0.01 0.70 -2.10 -1.19 -0.74 -0.26 0.67 8894 1 ## error[15] 0.36 0.00 0.30 -0.22 0.16 0.36 0.56 0.95 13643 1 ## error[16] 0.36 0.00 0.30 -0.22 0.16 0.36 0.56 0.95 13643 1 ## error[17] 0.98 0.00 0.27 0.45 0.79 0.98 1.16 1.52 15655 1 ## error[18] 1.98 0.00 0.27 1.45 1.79 1.98 2.16 2.52 15655 1 ## error[19] -0.40 0.00 0.28 -0.95 -0.59 -0.40 -0.21 0.15 14629 1 ## error[20] 1.60 0.00 0.28 1.05 1.41 1.60 1.79 2.15 14629 1 ## error[21] 1.22 0.00 0.33 0.58 1.00 1.22 1.44 1.84 12204 1 ## error[22] 2.22 0.00 0.33 1.58 2.00 2.22 2.44 2.84 12204 1 ## error[23] 0.83 0.00 0.39 0.06 0.57 0.83 1.09 1.60 10573 1 ## error[24] 0.83 0.00 0.39 0.06 0.57 0.83 1.09 1.60 10573 1 ## error[25] 3.00 0.01 0.90 1.23 2.40 2.99 3.59 4.78 8173 1 ## error[26] -1.38 0.01 0.80 -2.96 -1.92 -1.39 -0.86 0.21 8234 1 ## error[27] -0.91 0.00 0.44 -1.78 -1.21 -0.91 -0.62 -0.03 9291 1 ## error[28] 0.09 0.00 0.44 -0.78 -0.21 0.09 0.38 0.97 9291 1 ## error[29] 2.09 0.00 0.44 1.22 1.79 2.09 2.38 2.97 9291 1 ## error[30] -1.68 0.00 0.32 -2.31 -1.89 -1.68 -1.46 -1.05 11895 1 ## error[31] -0.68 0.00 0.32 -1.31 -0.89 -0.68 -0.46 -0.05 11895 1 ## error[32] -0.06 0.00 0.30 -0.64 -0.26 -0.06 0.14 0.52 13836 1 ## error[33] 0.94 0.00 0.30 0.36 0.74 0.94 1.14 1.52 13836 1 ## error[34] 1.94 0.00 0.30 1.36 1.74 1.94 2.14 2.52 13836 1 ## error[35] -1.44 0.00 0.31 -2.05 -1.65 -1.44 -1.23 -0.84 14248 1 ## error[36] -0.44 0.00 0.31 -1.05 -0.65 -0.44 -0.23 0.16 14248 1 ## error[37] 1.56 0.00 0.31 0.95 1.35 1.56 1.77 2.16 14248 1 ## error[38] 0.18 0.00 0.35 -0.52 -0.06 0.18 0.41 0.87 12929 1 ## error[39] 1.18 0.00 0.35 0.48 0.94 1.18 1.41 1.87 12929 1 ## error[40] -0.21 0.00 0.42 -1.03 -0.48 -0.21 0.08 0.61 11551 1 ## error[41] -1.33 0.00 0.43 -2.18 -1.62 -1.33 -1.04 -0.48 8764 1 ## error[42] 0.90 0.00 0.37 0.16 0.65 0.90 1.15 1.63 10648 1 ## error[43] -3.48 0.00 0.38 -4.24 -3.74 -3.48 -3.22 -2.73 11458 1 ## error[44] -2.48 0.00 0.38 -3.24 -2.74 -2.48 -2.22 -1.73 11458 1 ## error[45] -1.86 0.00 0.42 -2.69 -2.14 -1.86 -1.58 -1.03 11576 1 ## error[46] -0.86 0.00 0.42 -1.69 -1.14 -0.86 -0.58 -0.03 11576 1 ## error[47] -0.86 0.00 0.42 -1.69 -1.14 -0.86 -0.58 -0.03 11576 1 ## error[48] 0.14 0.00 0.42 -0.69 -0.14 0.14 0.42 0.97 11576 1 ## error[49] 0.14 0.00 0.42 -0.69 -0.14 0.14 0.42 0.97 11576 1 ## error[50] 0.14 0.00 0.42 -0.69 -0.14 0.14 0.42 0.97 11576 1 ## lp__ -59.45 0.02 1.48 -63.21 -60.18 -59.11 -58.34 -57.62 5192 1 ## ## Samples were drawn using NUTS(diag_e) at Fri Oct 02 12:01:32 2020. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). # plot the posterior in a # 95% probability interval # and 80% to contrast the dispersion plot(fit) ## &#39;pars&#39; not specified. Showing first 10 parameters by default. ## ci_level: 0.8 (80% intervals) ## outer_level: 0.95 (95% intervals) # traceplots rstan::traceplot(fit, pars = c(&quot;beta&quot;, &quot;sigma&quot;), inc_warmup = TRUE) # Gelman-Rubin-Brooks Convergence Criterion p1 &lt;- ggs_grb(ggs(fit, family = &quot;beta&quot;)) + theme_bw() + theme(panel.grid = element_blank()) p2 &lt;- ggs_grb(ggs(fit, family = &quot;sigma&quot;)) + theme_bw() + theme(panel.grid = element_blank()) p1 + p2 # autocorrelation p1 &lt;- ggs_autocorrelation(ggs(fit, family=&quot;beta&quot;)) + theme_bw() + theme(panel.grid = element_blank()) p2 &lt;- ggs_autocorrelation(ggs(fit, family=&quot;sigma&quot;)) + theme_bw() + theme(panel.grid = element_blank()) p1 + p2 # plot the posterior density plot.data &lt;- as.matrix(fit) plot_title &lt;- ggtitle(&quot;Posterior distributions&quot;, &quot;with medians and 80% intervals&quot;) mcmc_areas( plot.data, pars = c(&quot;beta[1]&quot;, &quot;beta[2]&quot;, &quot;beta[3]&quot;, &quot;sigma&quot;), prob = 0.8) + plot_title mcmc_areas( plot.data, pars = c(&quot;Rsquared&quot;), prob = 0.8) + plot_title # I prefer a posterior plot that includes prior and MLE # Expanded Posterior Plot fit.lm &lt;- summary(lm(Ch3Test ~ 1 + Ch1Test + Ch2Test, data=dat)) MLE &lt;- c(fit.lm$coefficients[,1], fit.lm$sigma**2, fit.lm$r.squared) prior_beta &lt;- function(x){dnorm(x, 0, 1000)} x.beta &lt;- seq(-10, 4.99, 0.01) prior.beta &lt;- data.frame(beta=x.beta, dens.beta = prior_beta(x.beta)) prior_sig &lt;- function(x){dgamma(x, 1, 1)} x.sig &lt;- seq(0.01, 2.5, 0.01) prior.sig &lt;- data.frame(sig=x.sig, dens.sig = prior_sig(x.sig)) cols &lt;- c(&quot;Posterior&quot;=&quot;#0072B2&quot;, &quot;Prior&quot;=&quot;#E69F00&quot;, &quot;MLE&quot;= &quot;black&quot;)#&quot;#56B4E9&quot;, &quot;#E69F00&quot; &quot;#CC79A7&quot; plot.data &lt;- as.data.frame(plot.data) p1 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=`beta[1]`, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[1], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ theme_bw()+ theme(panel.grid = element_blank()) p2 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=`beta[2]`, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[2], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0, 1))+ theme_bw()+ theme(panel.grid = element_blank()) p3 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=`beta[3]`, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[3], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0, 1))+ theme_bw()+ theme(panel.grid = element_blank()) p4 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=sigma, color=&quot;Posterior&quot;))+ geom_line(data=prior.sig, aes(x=sig, y=dens.sig, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[4], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ theme_bw()+ theme(panel.grid = element_blank()) p5 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=Rsquared, color=&quot;Posterior&quot;))+ geom_vline(aes(xintercept=MLE[5], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0, 1))+ theme_bw()+ theme(panel.grid = element_blank()) p1 + p2 + p3 + p4 + p5 + plot_layout(guides=&quot;collect&quot;) ## Warning: Removed 328 rows containing non-finite values (stat_density). ## Warning: Removed 1399 row(s) containing missing values (geom_path). ## Warning: Removed 1 rows containing non-finite values (stat_density). ## Warning: Removed 1399 row(s) containing missing values (geom_path). "],
["jags-model-for-regression-model.html", "6.2 JAGS Model for Regression Model", " 6.2 JAGS Model for Regression Model # model code jags.model &lt;- function(){ ############################################ # Prior distributions ############################################ beta.0 ~ dnorm(0, .001) # prior for the intercept beta.1 ~ dnorm(0, .001) # prior for coefficient 1 beta.2 ~ dnorm(0, .001) # prior for coefficient 2 tau.e ~ dgamma(1, 1) # prior for the error precision sigma.e &lt;- 1/sqrt(tau.e) # standard deviation of the errors ############################################ # Conditional distribution of the data # Via a regression model ############################################ for(i in 1:n){ y.prime[i] &lt;- beta.0 + beta.1*x1[i] + beta.2*x2[i] y[i] ~ dnorm(y.prime[i], tau.e) } ############################################ # Calculate R-squared ############################################ for(i in 1:n){ error[i] &lt;- y[i] - y.prime[i] } var.error &lt;- sd(error[])*sd(error[]) var.y &lt;- sd(y[])*sd(y[]) R.squared &lt;- 1 - (var.error/var.y) } # data dat &lt;- read.table(&quot;data/Chp4_Reg_Chapter_Tests.dat&quot;, header=T) mydata &lt;- list( n=nrow(dat), x1=dat$Ch1Test, x2=dat$Ch2Test, y =dat$Ch3Test ) # starting values start_values &lt;- function(){ list(&quot;tau.e&quot;=0.01, &#39;beta.0&#39;=0, &quot;beta.1&quot;=0, &quot;beta.2&quot;=0) } # vector of all parameters to save param_save &lt;- c(&quot;tau.e&quot;, &quot;beta.0&quot;, &quot;beta.1&quot;, &quot;beta.2&quot;, &quot;R.squared&quot;) # fit model fit &lt;- jags( model.file=jags.model, data=mydata, inits=start_values, parameters.to.save = param_save, n.iter=4000, n.burnin = 1000, n.chains = 4, n.thin=1, progress.bar = &quot;none&quot;) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 50 ## Unobserved stochastic nodes: 4 ## Total graph size: 262 ## ## Initializing model print(fit) ## Inference for Bugs model at &quot;C:/Users/noahp/AppData/Local/Temp/RtmpqeqVce/modeleb01a5c9e8.txt&quot;, fit using jags, ## 4 chains, each with 4000 iterations (first 1000 discarded) ## n.sims = 12000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## R.squared 0.584 0.019 0.536 0.578 0.590 0.597 0.601 1.040 4800 ## beta.0 -2.547 1.936 -6.349 -3.824 -2.562 -1.272 1.279 1.001 12000 ## beta.1 0.659 0.166 0.331 0.547 0.660 0.768 0.984 1.001 12000 ## beta.2 0.383 0.103 0.179 0.314 0.382 0.452 0.582 1.001 12000 ## tau.e 0.282 0.057 0.183 0.242 0.278 0.317 0.405 1.001 7600 ## deviance 207.604 2.948 204.099 205.503 206.954 208.969 214.799 1.001 4800 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 4.3 and DIC = 211.9 ## DIC is an estimate of expected predictive error (lower deviance is better). # extract posteriors for all chains jags.mcmc &lt;- as.mcmc(fit) R2jags::traceplot(jags.mcmc) # gelman-rubin-brook gelman.plot(jags.mcmc) # convert to single data.frame for density plot a &lt;- colnames(as.data.frame(jags.mcmc[[1]])) plot.data &lt;- data.frame(as.matrix(jags.mcmc, chains=T, iters = T)) colnames(plot.data) &lt;- c(&quot;chain&quot;, &quot;iter&quot;, a) plot_title &lt;- ggtitle(&quot;Posterior distributions&quot;, &quot;with medians and 80% intervals&quot;) mcmc_areas( plot.data, pars = c(&quot;beta.0&quot;, &quot;beta.1&quot;, &quot;beta.2&quot;, &quot;tau.e&quot;), prob = 0.8) + plot_title mcmc_areas( plot.data, pars = c(&quot;R.squared&quot;), prob = 0.8) + plot_title # Expanded Posterior Plot fit.lm &lt;- summary(lm(Ch3Test ~ 1 + Ch1Test + Ch2Test, data=dat)) MLE &lt;- c(fit.lm$coefficients[,1], 1/fit.lm$sigma**2, fit.lm$r.squared) prior_beta &lt;- function(x){dnorm(x, 0, 1000)} x.beta &lt;- seq(-5, 4.99, 0.01) prior.beta &lt;- data.frame(beta=x.beta, dens.beta = prior_beta(x.beta)) prior_tau &lt;- function(x){dgamma(x, 1, 1)} x.tau &lt;- seq(0.01, 0.50, 0.01) prior.tau &lt;- data.frame(tau=x.tau, dens.tau = prior_tau(x.tau)) cols &lt;- c(&quot;Posterior&quot;=&quot;#0072B2&quot;, &quot;Prior&quot;=&quot;#E69F00&quot;, &quot;MLE&quot;= &quot;black&quot;)#&quot;#56B4E9&quot;, &quot;#E69F00&quot; &quot;#CC79A7&quot; p1 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=beta.0, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[1], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ theme_bw()+ theme(panel.grid = element_blank()) p2 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=beta.1, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[2], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0, 1))+ theme_bw()+ theme(panel.grid = element_blank()) p3 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=beta.2, color=&quot;Posterior&quot;))+ geom_line(data=prior.beta, aes(x=beta, y=dens.beta, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[3], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0, 1))+ theme_bw()+ theme(panel.grid = element_blank()) p4 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=tau.e, color=&quot;Posterior&quot;))+ geom_line(data=prior.tau, aes(x=tau, y=dens.tau, color=&quot;Prior&quot;))+ geom_vline(aes(xintercept=MLE[4], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ theme_bw()+ theme(panel.grid = element_blank()) p5 &lt;- ggplot()+ geom_density(data=plot.data, aes(x=R.squared, color=&quot;Posterior&quot;))+ geom_vline(aes(xintercept=MLE[5], color=&quot;MLE&quot;))+ scale_color_manual(values=cols, name=NULL)+ lims(x=c(0.5, 0.65))+ theme_bw()+ theme(panel.grid = element_blank()) p1 + p2 + p3 + p4 + p5 + plot_layout(guides=&quot;collect&quot;) ## Warning: Removed 226 rows containing non-finite values (stat_density). ## Warning: Removed 899 row(s) containing missing values (geom_path). ## Warning: Removed 3 rows containing non-finite values (stat_density). ## Warning: Removed 899 row(s) containing missing values (geom_path). ## Warning: Removed 52 rows containing non-finite values (stat_density). "]
]
