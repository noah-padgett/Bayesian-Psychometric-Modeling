<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 13 Latent Class Analysis | Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy</title>
<meta name="author" content="R. Noah Padgett">
<meta name="description" content="Latent class analysis (LCA) takes a different approach to modeling latent variables than has been discussed in the previous chapters (especially CFA or IRT). The major distinguishing aspect of LCA...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 13 Latent Class Analysis | Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy">
<meta property="og:type" content="book">
<meta property="og:description" content="Latent class analysis (LCA) takes a different approach to modeling latent variables than has been discussed in the previous chapters (especially CFA or IRT). The major distinguishing aspect of LCA...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 13 Latent Class Analysis | Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy">
<meta name="twitter:description" content="Latent class analysis (LCA) takes a different approach to modeling latent variables than has been discussed in the previous chapters (especially CFA or IRT). The major distinguishing aspect of LCA...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Foundations</li>
<li><a class="" href="index.html"><span class="header-section-number">1</span> Index</a></li>
<li><a class="" href="chp2.html"><span class="header-section-number">2</span> Introduction to Bayesian Inference</a></li>
<li><a class="" href="conceptual-issues-in-bayesian-inference.html"><span class="header-section-number">3</span> Conceptual Issues in Bayesian Inference</a></li>
<li><a class="" href="normal-distribution-models.html"><span class="header-section-number">4</span> Normal Distribution Models</a></li>
<li><a class="" href="markov-chain-monte-carlo-estimation.html"><span class="header-section-number">5</span> Markov Chain Monte Carlo Estimation</a></li>
<li><a class="" href="regression.html"><span class="header-section-number">6</span> Regression</a></li>
<li class="book-part">Psychometrics</li>
<li><a class="" href="canonical-bayesian-psychometric-modeling.html"><span class="header-section-number">7</span> Canonical Bayesian Psychometric Modeling</a></li>
<li><a class="" href="classical-test-theory.html"><span class="header-section-number">8</span> Classical Test Theory</a></li>
<li><a class="" href="confirmatory-factor-analysis.html"><span class="header-section-number">9</span> Confirmatory Factor Analysis</a></li>
<li><a class="" href="model-evaluation.html"><span class="header-section-number">10</span> Model Evaluation</a></li>
<li><a class="" href="item-response-theory.html"><span class="header-section-number">11</span> Item Response Theory</a></li>
<li><a class="" href="missing-data-modeling.html"><span class="header-section-number">12</span> Missing Data Modeling</a></li>
<li><a class="active" href="latent-class-analysis.html"><span class="header-section-number">13</span> Latent Class Analysis</a></li>
<li><a class="" href="bayesian-networks.html"><span class="header-section-number">14</span> Bayesian Networks</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/noah-padgett/Bayesian-Psychometric-Modeling">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="latent-class-analysis" class="section level1" number="13">
<h1>
<span class="header-section-number">13</span> Latent Class Analysis<a class="anchor" aria-label="anchor" href="#latent-class-analysis"><i class="fas fa-link"></i></a>
</h1>
<p>Latent class analysis (LCA) takes a different approach to modeling latent variables than has been discussed in the previous chapters (especially CFA or IRT).
The major distinguishing aspect of LCA is that the latent variable is hypothesized to be a discrete random variable as opposed to a continuous random variable.
This shift in perspective is beneficial to researchers/analysts wishing to think categorically and discuss groups of observations/people/units as opposed to a dimension of possible differences.</p>
<p>LCA is often used in an exploratory nature to try to identify the number of “latent classes” or unobserved groups.
However, in the text, Levy and Mislevy discuss what they describe as a more “confirmatory” approach to LCA.
The major distinction is that they specify the number of classes to be known, and treat this chapter as a resource for how to estimate the model within a Bayesian framework.</p>
<p>To extend their work, we have added a section on model selection and provided resources for the interested reader.
But, in general, the topic of model selection in Bayesian LCA (and Bayesian SEM more generally) is still an ongoing area of research.
Many views exist on how to conduct model selection (if at all) and we will try to present an array of options that have been proposed.</p>
<div id="lca-model-specification" class="section level2" number="13.1">
<h2>
<span class="header-section-number">13.1</span> LCA Model Specification<a class="anchor" aria-label="anchor" href="#lca-model-specification"><i class="fas fa-link"></i></a>
</h2>
<p>LCA is a <em>finite mixture model</em>.
A mixture model is generally any statistical model that combines distributions to describe different subsets or aspects of the data.
For example, LCA is a mixture model that posits class specific item/indicator response probabilities.
Different classes have a different distribution or expected response on average.
Each unit of observation (e.g., person) is assumed to belong to 1 and only 1 class.
Because individuals can only belong to one class, the different classes of observations make up different subsets of the data used in the analysis.
One result of an LCA model is the ability to identify the likelihood that an individual belongs to a particular class which is sometimes called probabilistic clustering.</p>
<p>Let <span class="math inline">\(x_{ij}\)</span> be the observed value from respondent <span class="math inline">\(i=1, \ldots, N\)</span> on observable (item) <span class="math inline">\(j=1, \ldots, J\)</span>.
Because <span class="math inline">\(x\)</span> is binary, the observed value can be <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.
The latent class variable commonly denoted with a <span class="math inline">\(C\)</span> to represent the total number of latent classes.
Let <span class="math inline">\(\theta_i\)</span> represent the class for individual <span class="math inline">\(i\)</span>, where <span class="math inline">\(\theta_i \in \lbrace 1, \ldots, C\rbrace\)</span>.
Similar to IRT, LCA models the probability of the observed response.
However, LCA we estimate this value more directly because the value only depends on latent class membership instead of the value being indirectly estimated through item difficulties and discrimination parameters.
The model for the observed response being 1 is
<span class="math display">\[p(x_{ij} = 1) = \sum_{c=1}^Cp(x_{ij}=1\mid\theta_i=c,\pi_j)\gamma_c,\]</span>
where,</p>
<ul>
<li>
<span class="math inline">\(p(x_{ij}=1\mid\theta_i=c,\pi_i)\)</span> is class specific conditional response probability to item <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(\pi_j\)</span> represents the item parameters, in this case it is simply the conditional probability, but can be expanded to be a set of item parameters (e.g., IRT-like),</li>
<li>
<span class="math inline">\(\gamma_c\)</span> represents the class <em>mixing weight</em> or the class size parameter. The size of each class helps to identify how likely an individual in to be in any of the <span class="math inline">\(C\)</span> classes if we had no other information.</li>
<li>Additionally, the class mixing weights always sums to <span class="math inline">\(1\)</span>, that is</li>
</ul>
<p><span class="math display">\[\sum_{c=1}^C\gamma_c = \sum_{c=1}^Cp(\theta_i=c) = 1.\]</span></p>
<p>Another way of interpreting the mixing weight is as a class proportion.
This framing can sometimes make it easier to see that the indicator response probability is a weighted average of response probabilities over the <span class="math inline">\(C\)</span> classes.
The larger the class the more that class influences the expected response probabilities.</p>
<div id="lca-model-indeterminacy" class="section level3" number="13.1.1">
<h3>
<span class="header-section-number">13.1.1</span> LCA Model Indeterminacy<a class="anchor" aria-label="anchor" href="#lca-model-indeterminacy"><i class="fas fa-link"></i></a>
</h3>
<p>One common aspect of LCA than can be a bit of a headache at times if not carefully considered is an issue known as label switching.
LCA models discrete latent variables which do not have any inherent labels, as CFA/IRT model continuous latent variables that do not have any inherent scale/metric.</p>
</div>
<div id="model-likelihood" class="section level3" number="13.1.2">
<h3>
<span class="header-section-number">13.1.2</span> Model Likelihood<a class="anchor" aria-label="anchor" href="#model-likelihood"><i class="fas fa-link"></i></a>
</h3>
<p>The likelihood function for LCA follows a similar development as the likelihood function from CFA and IRT.
We assume that the individuals are independent (<span class="math inline">\(i\)</span>’s are exchangeable).
We assume that the responses to each item are conditionally (locally) independent (<span class="math inline">\(j\)</span>’s are exchangeable).
The joint probability conditional on the latent variable <span class="math inline">\(C\)</span> is</p>
<p><span class="math display">\[p(\mathbf{x}_i \vert \boldsymbol{\theta}, \boldsymbol{\pi}) = \prod_{i=1}^Np(\mathbf{x}_i \vert \theta_i=c, \boldsymbol{\pi}) = \prod_{i=1}^N\prod_{j=1}^Jp(x_{ij} \vert \theta_i=c, \pi_j).\]</span></p>
<p>The marginal probability when the observed data when we sum over the possible latent classes becomes</p>
<p><span class="math display">\[\begin{align*}
p(\mathbf{x}_i \vert \boldsymbol{\pi}, \boldsymbol{\gamma}) &amp;= \prod_{i=1}^N\sum_{c=1}^C p(\mathbf{x}_i \vert \theta_i=c, \boldsymbol{\pi})p(\theta_i = c \vert \gamma)\\
&amp;= \prod_{i=1}^N\left(\sum_{c=1}^C \left(\prod_{j=1}^J p(x_{ij} \vert \theta_i=c, \pi_j)\right)p(\theta_i = c \vert \gamma)\right)
\end{align*}
\]</span></p>
</div>
</div>
<div id="bayesian-lca-model-specification" class="section level2" number="13.2">
<h2>
<span class="header-section-number">13.2</span> Bayesian LCA Model Specification<a class="anchor" aria-label="anchor" href="#bayesian-lca-model-specification"><i class="fas fa-link"></i></a>
</h2>
<p>For the Bayesian formulation of the LCA model, the construction will be carried out in pieces similar to previous chapters.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:chp13-dag-1"></span>
<img src="dag/chp13-lca1.png" alt="DAG for a general latent class analysis model" width="50%" height="90%"><p class="caption">
Figure 13.1: DAG for a general latent class analysis model
</p>
</div>
<div id="distribution-of-observed-indicators" class="section level3" number="13.2.1">
<h3>
<span class="header-section-number">13.2.1</span> Distribution of Observed Indicators<a class="anchor" aria-label="anchor" href="#distribution-of-observed-indicators"><i class="fas fa-link"></i></a>
</h3>
<p>First, the distribution of the observed variables is specified as a product of independent probabilities.
That is, the observed data distribution is <em>categorical(.)</em>.
Or</p>
<p><span class="math display">\[\begin{align*}
p(\mathbf{x}\vert \boldsymbol{\theta}, \boldsymbol{\pi})&amp;= \prod_{i=1}^N p(\mathbf{x}_i\vert \theta_i, \boldsymbol{\pi}) = \prod_{i=1}^N \prod_{j=1}^J p(x_{ij}\vert \theta_i, \boldsymbol{\pi}_j),\\
x_{ij} &amp;\sim \mathrm{Categorical}(\pi_{cj})\\
\end{align*}\]</span>
where the model holds for observables taking values coded as <span class="math inline">\(1,...,K\)</span> with the categorical indicators.
One of the major changes from an IRT model is that the latent variables are categorical, resulting in a different distribution for the latent variable.
The <em>Dirichlet</em> distribution is commonly used as the prior for the categorical latent variables.
The Dirichlet distribution is a generalization of the Beta distribution to more than two district outcomes.
The distribution models the categorical data as the likelihood or propensity to be one of the categoricals.</p>
</div>
<div id="prior-distributions" class="section level3" number="13.2.2">
<h3>
<span class="header-section-number">13.2.2</span> Prior Distributions<a class="anchor" aria-label="anchor" href="#prior-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>The LCA model, as described here, contains two major types of parameters.
That is, (1) the latent class status for each respondent and (2) the class specific category proportions.
These two parameter types are vectors over respondents and items, respectively.
The joint prior distribution can be generally described as
<span class="math display">\[p(\theta, \pi) = p(\theta)p(\pi),\]</span>
due to assuming independence between these two types of parameters.
Independence is a logical assumption and aligns with the IRT and CFA traditions that latent variable values are independent of the measurement model parameters.</p>
<p>The prior for the latent variables is represents the prior for the discrete groups respondents are assumed to belong to.
A common prior is placed over all respondents
<span class="math display">\[p(\theta)=\prod_{i=1}^np(\theta_i\vert\boldsymbol{\theta}_p),\]</span>
where <span class="math inline">\(\boldsymbol\theta_p\)</span> represents the hyperpriors defining the conditions of the categorical latent variables.
The vector of parameters <span class="math inline">\(\boldsymbol\theta_p = \boldsymbol\gamma = (\gamma_1, \gamma_2, ..., \gamma_C)\)</span>, where <span class="math inline">\(C\)</span> is the number of latent groups.
Stated in another way,
<span class="math display">\[\theta_i | \boldsymbol\gamma \sim \mathrm{Categorical}(\boldsymbol\gamma).\]</span></p>
<p>The hyperprior for the categorical latent variable is also commonly given a prior distribution.
The <span class="math inline">\(\boldsymbol\gamma\)</span> parameters represent the class proportions and a prior on these parameters is useful when these class proportions are not known.
The prior is
<span class="math display">\[\boldsymbol\gamma \sim \mathrm{Dirichlet}(\boldsymbol\alpha_\gamma),\]</span>
where <span class="math inline">\(\boldsymbol\alpha_\gamma = (\alpha_{\gamma 1}, \alpha_{\gamma 2}, ..., \alpha_{\gamma C}).\)</span>
The Dirichlet distribution is a generalization of the Beta distribution to more than two categories.
This allows for a useful representation of the probabilities with well known statistical and sampling properties.</p>
<p>The priors for the measurement model parameters (<span class="math inline">\(\boldsymbol\pi\)</span>) are commonly defined at the item level instead of jointly over all items:
<span class="math display">\[p(\boldsymbol\pi) = \prod_{j=1}^Jp(\boldsymbol\pi_j\vert\boldsymbol\alpha_\pi),\]</span>
where <span class="math inline">\(\boldsymbol\alpha_\pi\)</span> defines the hyperpriors for the measurement model parameters.
The measurement model commonly utilizes either dichotomous or categorical indicators which leads to the use of either the Beta distribution or Dirichlet distribution for the priors.</p>
</div>
<div id="full-model-specification" class="section level3" number="13.2.3">
<h3>
<span class="header-section-number">13.2.3</span> Full Model Specification<a class="anchor" aria-label="anchor" href="#full-model-specification"><i class="fas fa-link"></i></a>
</h3>
<p>The full model specification can be shown as follows:</p>
<p><span class="math display">\[
\begin{align*}
p(\boldsymbol\theta, \boldsymbol\gamma, \boldsymbol\pi) &amp;\propto p(\mathbf{x} \vert \boldsymbol\theta, \boldsymbol\gamma, \boldsymbol\pi) p(\boldsymbol\theta, \boldsymbol\gamma, \boldsymbol\pi)\\
&amp;= p(\mathbf{x} \vert \boldsymbol\theta, \boldsymbol\gamma, \boldsymbol\pi) p(\boldsymbol\theta) p(\boldsymbol\gamma) p(\boldsymbol\pi)\\
&amp;= \prod_{i=1}^N \prod_{j=1}^J p(x_{ij}\vert \theta_i, \boldsymbol{\pi}_j)p(\theta_i \vert \boldsymbol\gamma)p(\boldsymbol\gamma) \prod_{c=1}^Cp(\boldsymbol\pi_{cj})\\
(x_{ij} \vert \theta_i=c, \boldsymbol{\pi}_j) &amp;\sim \mathrm{Categorical}(\boldsymbol{\pi}_{cj}), \mathrm{for}\ i=1, ...,n,\ j=1, ...,J,\\
\theta_i \vert \boldsymbol{\gamma} &amp;\sim \mathrm{Categorical}(\boldsymbol{\gamma})\ \mathrm{for}\ i=1, ...,n,\\
\boldsymbol\gamma &amp;\sim \mathrm{Dirichlet}(\boldsymbol\alpha_{\gamma}),\\
\boldsymbol\pi_{cj} &amp;\sim \mathrm{Dirichlet}(\boldsymbol\alpha_{\pi_c})\ \mathrm{for}\ c=1, ..., C, j=1, ..., J.
\end{align*}
\]</span></p>
</div>
</div>
<div id="academic-cheating-example" class="section level2" number="13.3">
<h2>
<span class="header-section-number">13.3</span> Academic Cheating Example<a class="anchor" aria-label="anchor" href="#academic-cheating-example"><i class="fas fa-link"></i></a>
</h2>
<p>The academic cheating example is discussed on pages 328-340. The last few pages pertain mainly to model fit/evaluation and a discussion on indeterminacy in the model.
Some of these points will be left to the reader for in-text learning.
The major motivation for this current development is applying the model from pages 329-330, and replicating results (p.336).</p>
<div id="estimating-using-jags" class="section level3" number="13.3.1">
<h3>
<span class="header-section-number">13.3.1</span> Estimating using JAGS<a class="anchor" aria-label="anchor" href="#estimating-using-jags"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb413"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">jags.model.lsat</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span><span class="op">{</span>

<span class="co">#########################################</span>
<span class="co"># Specify the item response measurement model for the observables</span>
<span class="co">#########################################</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span>
  <span class="kw">for</span><span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">J</span><span class="op">)</span><span class="op">{</span>
    <span class="va">x</span><span class="op">[</span><span class="va">i</span>,<span class="va">j</span><span class="op">]</span> <span class="op">~</span> <span class="fu">dbern</span><span class="op">(</span><span class="va">pi</span><span class="op">[</span><span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="va">j</span><span class="op">]</span><span class="op">)</span>                  <span class="co"># distribution for each observable conditional on latent class assignment theta</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="co">##########################################</span>
<span class="co"># Specify the (prior) distribution for the latent variables</span>
<span class="co">##########################################</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">{</span>
  <span class="va">theta</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">~</span> <span class="fu">dcat</span><span class="op">(</span><span class="va">gamma</span><span class="op">[</span><span class="op">]</span><span class="op">)</span>  <span class="co"># distribution for the latent variables is categorical</span>
<span class="op">}</span>

<span class="va">gamma</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">C</span><span class="op">]</span> <span class="op">~</span> <span class="fu">ddirich</span><span class="op">(</span><span class="va">alpha_gamma</span><span class="op">[</span><span class="op">]</span><span class="op">)</span>
<span class="kw">for</span><span class="op">(</span><span class="va">c</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">C</span><span class="op">)</span><span class="op">{</span>
  <span class="va">alpha_gamma</span><span class="op">[</span><span class="va">c</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span>
<span class="op">}</span>

<span class="co">##########################################</span>
<span class="co"># Specify the prior distribution for the measurement model parameters</span>
<span class="co"># Measurement model consists of class specific response probabilities</span>
<span class="co">##########################################</span>
<span class="kw">for</span><span class="op">(</span><span class="va">c</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">C</span><span class="op">)</span><span class="op">{</span>
  <span class="kw">for</span><span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">J</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">{</span>
    <span class="va">pi</span><span class="op">[</span><span class="va">c</span>,<span class="va">j</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>
<span class="va">pi</span><span class="op">[</span><span class="fl">1</span>,<span class="va">J</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span>
<span class="va">pi</span><span class="op">[</span><span class="fl">2</span>,<span class="va">J</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span>
  

<span class="op">}</span> <span class="co"># closes the model</span>

<span class="co"># initial values</span>
<span class="va">start_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"gamma"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.9</span>, <span class="fl">0.1</span><span class="op">)</span>,
       <span class="st">"pi"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.37</span>, <span class="fl">.20</span>, <span class="fl">.06</span>, <span class="fl">.04</span>, <span class="fl">.41</span>, <span class="fl">.47</span>, <span class="fl">.19</span>, <span class="fl">.32</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"gamma"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span>,
       <span class="st">"pi"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.58</span>, <span class="fl">.62</span>, <span class="fl">.69</span>, <span class="fl">.77</span>, <span class="fl">.81</span>, <span class="fl">.84</span>, <span class="fl">.88</span>, <span class="fl">.90</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"gamma"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span>,
       <span class="st">"pi"</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.32</span>, <span class="fl">.49</span>, <span class="fl">.29</span>, <span class="fl">.61</span>, <span class="fl">.48</span>, <span class="fl">.54</span>, <span class="fl">.44</span>, <span class="fl">.70</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>

<span class="co"># vector of all parameters to save</span>
<span class="va">param_save</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gamma"</span>, <span class="st">"pi"</span><span class="op">)</span>

<span class="co"># dataset</span>
<span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/Cheat.dat"</span>, header<span class="op">=</span><span class="cn">F</span><span class="op">)</span>

<span class="va">mydata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, 
  J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>,
  C<span class="op">=</span><span class="fl">2</span>,
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
<span class="op">)</span>

<span class="co"># fit model</span>
<span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">jags</span><span class="op">(</span>
  model.file<span class="op">=</span><span class="va">jags.model.lsat</span>,
  data<span class="op">=</span><span class="va">mydata</span>,
  inits<span class="op">=</span><span class="va">start_values</span>,
  parameters.to.save <span class="op">=</span> <span class="va">param_save</span>,
  n.iter<span class="op">=</span><span class="fl">2000</span>,
  n.burnin <span class="op">=</span> <span class="fl">1000</span>,
  n.chains <span class="op">=</span> <span class="fl">3</span>,
  progress.bar <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></code></pre></div>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 1276
##    Unobserved stochastic nodes: 328
##    Total graph size: 2885
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb416"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></code></pre></div>
<pre><code>## Inference for Bugs model at "C:/Users/noahp/AppData/Local/Temp/Rtmp4WWggD/model5c285c9023ab.txt", fit using jags,
##  3 chains, each with 2000 iterations (first 1000 discarded)
##  n.sims = 3000 iterations saved
##          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
## gamma[1]   0.861   0.063   0.757   0.839   0.870   0.895   0.937 1.239    73
## gamma[2]   0.139   0.063   0.063   0.105   0.130   0.161   0.243 1.041    77
## pi[1,1]    0.033   0.018   0.003   0.020   0.032   0.044   0.073 1.058    80
## pi[2,1]    0.626   0.147   0.359   0.526   0.622   0.728   0.913 1.028   180
## pi[1,2]    0.042   0.021   0.004   0.026   0.041   0.056   0.086 1.005   610
## pi[2,2]    0.652   0.139   0.382   0.560   0.653   0.746   0.919 1.050    92
## pi[1,3]    0.043   0.015   0.016   0.033   0.042   0.052   0.074 1.026   640
## pi[2,3]    0.252   0.084   0.112   0.190   0.244   0.305   0.439 1.011   190
## pi[1,4]    0.186   0.027   0.136   0.170   0.186   0.204   0.238 1.065   230
## pi[2,4]    0.406   0.096   0.233   0.338   0.399   0.469   0.608 1.002  1100
## deviance 735.481  29.161 681.307 718.188 734.787 751.019 789.102 1.004  3000
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 425.4 and DIC = 1160.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb418"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># extract posteriors for all chains</span>
<span class="va">jags.mcmc</span> <span class="op">&lt;-</span> <span class="fu">as.mcmc</span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>
<span class="co"># the below two plots are too big to be useful given the 1000 observations.</span>
<span class="co">#R2jags::traceplot(jags.mcmc)</span>

<span class="co"># gelman-rubin-brook</span>
<span class="co">#gelman.plot(jags.mcmc)</span>

<span class="co"># convert to single data.frame for density plot</span>
<span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">jags.mcmc</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>
<span class="va">plot.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">jags.mcmc</span>, chains<span class="op">=</span><span class="cn">T</span>, iters <span class="op">=</span> <span class="cn">T</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">plot.data</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"chain"</span>, <span class="st">"iter"</span>, <span class="va">a</span><span class="op">)</span>


<span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-diagnostics.html">mcmc_acf</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"gamma["</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-1.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb419"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-traces.html">mcmc_trace</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"gamma["</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-2.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb420"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggmcmc</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggmcmc/man/ggs_grb.html">ggs_grb</a></span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">jags.mcmc</span><span class="op">)</span>, family<span class="op">=</span><span class="st">"gamma"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-3.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb421"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mcmc_areas</span><span class="op">(</span><span class="va">plot.data</span>, pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"gamma["</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="st">"]"</span><span class="op">)</span><span class="op">)</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-4.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb422"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-diagnostics.html">mcmc_acf</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[1,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-5.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-traces.html">mcmc_trace</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[1,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-6.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb424"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mcmc_areas</span><span class="op">(</span> <span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[1,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-7.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb425"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-diagnostics.html">mcmc_acf</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[2,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-8.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb426"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-traces.html">mcmc_trace</a></span><span class="op">(</span><span class="va">plot.data</span>,pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[2,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-9.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb427"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mcmc_areas</span><span class="op">(</span><span class="va">plot.data</span>, pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[2,"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="st">"]"</span><span class="op">)</span><span class="op">)</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-10.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb428"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggmcmc</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggmcmc/man/ggs_grb.html">ggs_grb</a></span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">jags.mcmc</span><span class="op">)</span>, family<span class="op">=</span><span class="st">"pi"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-jags-11.png" width="90%" height="90%"></div>
</div>
<div id="estimation-using-stan" class="section level3" number="13.3.2">
<h3>
<span class="header-section-number">13.3.2</span> Estimation using Stan<a class="anchor" aria-label="anchor" href="#estimation-using-stan"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb429"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model_lca</span> <span class="op">&lt;-</span> <span class="st">[1717 chars quoted with ''']</span>


<span class="co"># initial values</span>
<span class="va">start_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>gamma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span>,
       pi<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.37</span>, <span class="fl">.20</span>, <span class="fl">.06</span>, <span class="fl">.04</span>, <span class="fl">.41</span>, <span class="fl">.47</span>, <span class="fl">.19</span>, <span class="fl">.32</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>gamma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.8</span><span class="op">)</span>,
       pi<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.58</span>, <span class="fl">.62</span>, <span class="fl">.69</span>, <span class="fl">.77</span>, <span class="fl">.81</span>, <span class="fl">.84</span>, <span class="fl">.88</span>, <span class="fl">.90</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>gamma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.4</span>, <span class="fl">0.6</span><span class="op">)</span>,
       pi<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/structure.html">structure</a></span><span class="op">(</span>.Data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.32</span>, <span class="fl">.49</span>, <span class="fl">.29</span>, <span class="fl">.61</span>, <span class="fl">.48</span>, <span class="fl">.54</span>, <span class="fl">.44</span>, <span class="fl">.70</span><span class="op">)</span>, .Dim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>

<span class="co"># dataset</span>
<span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/Cheat.dat"</span>, header<span class="op">=</span><span class="cn">F</span><span class="op">)</span>

<span class="va">mydata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, 
  J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>,
  C <span class="op">=</span> <span class="fl">2</span>,
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
<span class="op">)</span>



<span class="co"># Next, need to fit the model</span>
<span class="co">#   I have explicitly outlined some common parameters</span>
<span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">stan</span><span class="op">(</span>
  model_code <span class="op">=</span> <span class="va">model_lca</span>, <span class="co"># model code to be compiled</span>
  data <span class="op">=</span> <span class="va">mydata</span>,          <span class="co"># my data</span>
  <span class="co">#init = start_values,    # starting values</span>
  chains <span class="op">=</span> <span class="fl">1</span>,             <span class="co"># number of Markov chains</span>
  warmup <span class="op">=</span> <span class="fl">2000</span>,          <span class="co"># number of warm up iterations per chain</span>
  iter <span class="op">=</span> <span class="fl">4000</span>,            <span class="co"># total number of iterations per chain</span>
  cores <span class="op">=</span> <span class="fl">1</span>,              <span class="co"># number of cores (could use one per chain)</span>
  <span class="co">#refresh = 0             # no progress shown</span>
<span class="op">)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0.000971 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 9.71 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup)
## Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)
## Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)
## Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)
## Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)
## Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)
## Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)
## Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)
## Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)
## Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)
## Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)
## Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 34.55 seconds (Warm-up)
## Chain 1:                30.385 seconds (Sampling)
## Chain 1:                64.935 seconds (Total)
## Chain 1:</code></pre>
<div class="sourceCode" id="cb431"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># first get a basic breakdown of the posteriors</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span>,pars <span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gamma"</span>, <span class="st">"gamma_ord"</span>, <span class="st">"pi"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## Inference for Stan model: anon_model.
## 1 chains, each with iter=4000; warmup=2000; thin=1; 
## post-warmup draws per chain=2000, total post-warmup draws=2000.
## 
##               mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
## gamma[1]     -1.50    0.06 1.43 -4.48 -2.26 -1.50 -0.79  1.60   549    1
## gamma_ord[1]  0.12    0.00 0.10  0.01  0.05  0.09  0.16  0.42   548    1
## gamma_ord[2]  0.88    0.00 0.10  0.58  0.84  0.91  0.95  0.99   548    1
## pi[1,1]       0.43    0.01 0.28  0.02  0.19  0.38  0.64  0.96   893    1
## pi[1,2]       0.44    0.01 0.28  0.01  0.18  0.41  0.67  0.96   922    1
## pi[1,3]       0.36    0.01 0.26  0.02  0.14  0.31  0.55  0.93   874    1
## pi[1,4]       0.48    0.01 0.29  0.03  0.23  0.46  0.73  0.97  1193    1
## pi[2,1]       0.08    0.00 0.04  0.01  0.05  0.08  0.11  0.15   777    1
## pi[2,2]       0.09    0.00 0.04  0.01  0.07  0.10  0.12  0.17   817    1
## pi[2,3]       0.05    0.00 0.03  0.00  0.03  0.05  0.06  0.10   631    1
## pi[2,4]       0.18    0.00 0.06  0.04  0.15  0.19  0.22  0.28   532    1
## 
## Samples were drawn using NUTS(diag_e) at Sun Jul 17 14:53:30 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<div class="sourceCode" id="cb433"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># plot the posterior in a</span>
<span class="co">#  95% probability interval</span>
<span class="co">#  and 80% to contrast the dispersion</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>,pars <span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gamma"</span>, <span class="st">"pi"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## ci_level: 0.8 (80% intervals)</code></pre>
<pre><code>## outer_level: 0.95 (95% intervals)</code></pre>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-stan-1.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb436"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># traceplots</span>
<span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">fit</span>,pars <span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gamma"</span>, <span class="st">"pi"</span><span class="op">)</span>, inc_warmup <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-stan-2.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb437"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gelman-Rubin-Brooks Convergence Criterion</span>
<span class="fu">ggs_grb</span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">fit</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gamma"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## Error in ggs_grb(ggs(fit, family = c("gamma"))): At least two chains are required</code></pre>
<div class="sourceCode" id="cb439"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggs_grb</span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">fit</span>, family <span class="op">=</span> <span class="st">"pi"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## Error in ggs_grb(ggs(fit, family = "pi")): At least two chains are required</code></pre>
<div class="sourceCode" id="cb441"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># autocorrelation</span>
<span class="fu">ggs_autocorrelation</span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">fit</span>, family<span class="op">=</span><span class="st">"gamma"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-stan-3.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb442"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggs_autocorrelation</span><span class="op">(</span><span class="fu">ggs</span><span class="op">(</span><span class="va">fit</span>, family<span class="op">=</span><span class="st">"pi"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-stan-4.png" width="90%" height="90%"></div>
<div class="sourceCode" id="cb443"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># plot the posterior density</span>
<span class="va">plot.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>

<span class="va">plot_title</span> <span class="op">&lt;-</span> <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Posterior distributions"</span>,
                      <span class="st">"with medians and 80% intervals"</span><span class="op">)</span>
<span class="fu">mcmc_areas</span><span class="op">(</span>
  <span class="va">plot.data</span>,
  pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"gamma["</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="st">"]"</span><span class="op">)</span>,
  prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span>
  <span class="va">plot_title</span></code></pre></div>
<pre><code>## Error in `select_parameters()`:
## ! Some 'pars' don't match parameter names: gamma[2] FALSE</code></pre>
<div class="sourceCode" id="cb445"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mcmc_areas</span><span class="op">(</span>
  <span class="va">plot.data</span>,
  pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[1,"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span>,<span class="st">"]"</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"pi[2,"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span>,<span class="st">"]"</span><span class="op">)</span><span class="op">)</span>,
  prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span>
  <span class="va">plot_title</span></code></pre></div>
<div class="inline-figure"><img src="bookdown-BPM_files/figure-html/chp13-academic-cheating-stan-5.png" width="90%" height="90%"></div>
</div>
</div>
<div id="extending-lca" class="section level2" number="13.4">
<h2>
<span class="header-section-number">13.4</span> Extending LCA<a class="anchor" aria-label="anchor" href="#extending-lca"><i class="fas fa-link"></i></a>
</h2>
<p>In LCA, the mixing of distributions can be generalized to include more complex components such as factor models to model the response process within class.
For example, we can have factor mixture models where different CFA models hold for different subsets of the population.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="missing-data-modeling.html"><span class="header-section-number">12</span> Missing Data Modeling</a></div>
<div class="next"><a href="bayesian-networks.html"><span class="header-section-number">14</span> Bayesian Networks</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#latent-class-analysis"><span class="header-section-number">13</span> Latent Class Analysis</a></li>
<li>
<a class="nav-link" href="#lca-model-specification"><span class="header-section-number">13.1</span> LCA Model Specification</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#lca-model-indeterminacy"><span class="header-section-number">13.1.1</span> LCA Model Indeterminacy</a></li>
<li><a class="nav-link" href="#model-likelihood"><span class="header-section-number">13.1.2</span> Model Likelihood</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bayesian-lca-model-specification"><span class="header-section-number">13.2</span> Bayesian LCA Model Specification</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#distribution-of-observed-indicators"><span class="header-section-number">13.2.1</span> Distribution of Observed Indicators</a></li>
<li><a class="nav-link" href="#prior-distributions"><span class="header-section-number">13.2.2</span> Prior Distributions</a></li>
<li><a class="nav-link" href="#full-model-specification"><span class="header-section-number">13.2.3</span> Full Model Specification</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#academic-cheating-example"><span class="header-section-number">13.3</span> Academic Cheating Example</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#estimating-using-jags"><span class="header-section-number">13.3.1</span> Estimating using JAGS</a></li>
<li><a class="nav-link" href="#estimation-using-stan"><span class="header-section-number">13.3.2</span> Estimation using Stan</a></li>
</ul>
</li>
<li><a class="nav-link" href="#extending-lca"><span class="header-section-number">13.4</span> Extending LCA</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/noah-padgett/Bayesian-Psychometric-Modeling/blob/master/13-lca.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/noah-padgett/Bayesian-Psychometric-Modeling/edit/master/13-lca.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Bayesian Psychometric Modeling (2016) by Roy Levy and Robert J. Mislevy</strong>" was written by R. Noah Padgett. It was last built on 2022-07-17.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
