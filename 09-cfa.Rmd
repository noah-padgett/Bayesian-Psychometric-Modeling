# Confirmatory Factor Analysis

The full Bayesian specification of a _general_ CFA model for all associated unknowns is as follows.
This includes probability statements, notation, parameters, likelihood, priors, and hyperparameters.
The observed data is defined as the $n\times J$ matrix $\mathbf{X}$ for the $J$ observed measures.
The CFA model parameters are defined as

\begin{align*}
\mathbf{x}_i &= \tau + \Lambda\xi_i + \varepsilon_i\\
\Sigma (\mathbf{x}) &= \Lambda\Phi\Lambda^{\prime} + \Psi
\end{align*}


* $\Xi$ is the $n\times M$ matrix of latent variable scores on the $M$ latent variables for the $n$ respondents/subjects. For an single subject, $\xi_i$ represents the vector of scores on the latent variable(s). Values (location, scale, orientation, etc.) or $\xi_i$ are conditional on (1) $\kappa$, the $M\times 1$ vector of latent variable means, and (2) $\Phi$, the $M\times M$ covariance matrix of variable variables;
* $\tau$ is the $J\times 1$ vector of observed variable intercepts which is the expected value for the observed measures when the latent variable(s) are all $0$;
* $\Lambda$ is the $J\times M$ matrix of factor loadings where the $j$th row and $m$th column represents the factor loading of the $j$th observed variable on the $m$th latent variable;
* $\delta_i$ is the $J\times 1$ vector of errors, where $E(\delta_i)=\mathbf{0}$ with $\mathrm{var}(\delta_i)=\Psi$ which is the $J\times J$ error covariance matrix.

\begin{align*}
p(\Xi, \kappa, \Phi, \tau, \Lambda, \Psi\mid \mathbf{X}) &\propto p(\mathbf{X}\mid\Xi, \kappa, \Phi, \tau, \Lambda, \Psi)p(\Xi, \kappa, \Phi, \tau, \Lambda, \Psi)\\
  &= p(\mathbf{X}\mid\Xi, \kappa, \Phi, \tau, \Lambda, \Psi) p(\Xi\mid\kappa, \Phi) p(\kappa) p(\Phi) p(\tau) p(\Lambda) p(\Psi)\\
  &= \prod_{i=1}^{n}\prod_{j=1}^J\prod_{m=1}^M p(x_{ij}\mid\xi_i, \tau_j,\lambda_j, \psi_{jj}) p(\xi_i\mid\kappa, \Phi) p(\kappa_m) p(\Phi) p(\tau_j) p(\lambda_j) p(\psi_{jj})
\end{align*}
where

\begin{align*}
x_{ij}\mid\xi_i, \tau_j,\lambda_j, \psi_{jj} &\sim \mathrm{Normal}(\tau_j+\xi_i\lambda^{\prime}_j, \psi_{jj}),\ \mathrm{for}\ i=1, \cdots, n,\ j = 1, \cdots, J;\\
\xi_i\mid\kappa, \Phi &\sim \mathrm{Normal}(\kappa, \Phi),\ \mathrm{for}\ i=1, \cdots, n;\\
\kappa_m &\sim \mathrm{Normal}(\mu_{\kappa},\sigma^2_{\kappa}),\ \mathrm{for}\ m = 1, \cdots, M;\\
\Phi &\sim \mathrm{Inverse-Wishart}(\Phi_0, d);\\
\tau_j &\sim \mathrm{Normal}(\mu_{\tau},\sigma^2_{\tau}),\ \mathrm{for}\ j = 1, \cdots, J;\\
\lambda_{j,m} &\sim \mathrm{Normal}(\mu_{\lambda}, \sigma^2_{\lambda}),\ \mathrm{for}\ j = 1, \cdots, J,\ m = 1, \cdots, M;\\
\psi_{jj} &\sim \mathrm{Inverse-Gamma}(\nu_{\psi}/2, \nu_{\psi}\psi_0/2),\ \mathrm{for}\ j=1, \cdots, J.
\end{align*}
With the hyperparameters that are supplied by the analyst being defined as

* $\mu_{\kappa}$ is the prior mean for the latent variable,
* $\sigma^2_{\kappa}$ is the prior variance for the latent variable,
* $\Phi_0$ is the prior expectation for the covariance matrix among latent variables,
* $d$ represents a dispersion parameter reflecting the magnitude of our beliefs about $\Phi_0$,
* $\mu_{\tau}$ is the prior mean for the intercepts which reflects our knowledge about the location of the observed variables,
* $\sigma^2_{\tau}$ is a measure of how much weight we want to give to the prior mean,
* $\mu_{\lambda}$ is the prior mean for the factor loadings which can vary over items and latent variables,
* $\sigma^2_{\lambda}$ is the measure of dispersion for the the factor loadings, where lower variances indicate a stronger belief about the values for the loadings,
* $\nu_{\psi}$ is the measure of location for the gamma prior indicating our expectation for the magnitude of the error variance,
* $\psi_0$ is our uncertainty with respect to the location we selected for the variance, and
* Alternatively, we could place a prior on $\Psi$ instead of the individual residual variances. This would mean we would be placing a prior on the error-covariance matrix similar to how we specified a prior for latent variance covariance matrix.


## Single Latent Variable Model

Here we consider the model in section 9.3 which is a CFA model with 1 latent variable and 5 observed indicators.
The graphical representation of these factor models get pretty complex pretty quickly, but for this example I have reproduced a version of Figure 9.3b, shown below.

```{r chp9-dag-1, echo=FALSE,fig.align='center', out.width = "75%",fig.cap='DAG for CFA model with 1 latent variable'}
knitr::include_graphics(paste0(w.d,'/dag/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```

However, as the authors noted, the path diagram tradition of conveying models is also very useful in discussing and describing the model, which I give next.


```{r chp9-pathdiag-1, echo=FALSE,fig.align='center',fig.cap='Path diagram for CFA model with 1 latent variable'}
knitr::include_graphics(paste0(w.d,'/path-diagram/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```

For completeness, I have included the model specification diagram that more concretely connects the DAG and path diagram to the assumed distributions and priors.

```{r chp9-spec-1, echo=FALSE,fig.align='center',fig.cap='Model specification diagram for the CFA model with 1 latent factor'}
knitr::include_graphics(paste0(w.d,'/model-spec/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```


## JAGS - Single Latent Variable

```{r chp9-cfa-fit-jags-1, warnings=T, message=T, error=T, cache=TRUE}

# model code
jags.model.cfa1 <- function(){

  ########################################
  # Specify the factor analysis measurement model for the observables
  ##############################################
  for (i in 1:n){
    for(j in 1:J){
      mu[i,j] <- tau[j] + ksi[i]*lambda[j]      # model implied expectation for each observable
      x[i,j] ~ dnorm(mu[i,j], inv.psi[j])    # distribution for each observable
    }
  }
  
  
  ##################################
  # Specify the (prior) distribution for the latent variables
  ####################################
  for (i in 1:n){
    ksi[i] ~ dnorm(kappa, inv.phi)  # distribution for the latent variables
  }
  
  
  ######################################
  # Specify the prior distribution for the parameters that govern the latent variables
  ###################################
  kappa <- 0              # Mean of factor 1
  inv.phi ~ dgamma(5, 10) # Precision of factor 1
  phi <- 1/inv.phi        # Variance of factor 1
  
  
  ########################################
  # Specify the prior distribution for the measurement model parameters
  ########################################
  for(j in 1:J){
    tau[j] ~ dnorm(3, .1)        # Intercepts for observables
  	inv.psi[j] ~ dgamma(5, 10) # Precisions for observables
  	psi[j] <- 1/inv.psi[j]   # Variances for observables
  }
  
  lambda[1] <- 1.0              # loading fixed to 1.0 
  for (j in 2:J){
  	lambda[j] ~ dnorm(1, .1)    # prior distribution for the remaining loadings
  }
}
# data must be in a list
dat <- read.table("code/CFA-One-Latent-Variable/Data/IIS.dat", header=T)

mydata <- list(
  n = 500, J = 5,
  x = as.matrix(dat)
)


# initial values
start_values <- list(
  list("tau"=c(.1, .1, .1, .1, .1),
       "lambda"=c(NA, 0, 0, 0, 0),
       "inv.phi"=1,
       "inv.psi"=c(1, 1, 1, 1, 1)),
  list("tau"=c(3, 3, 3, 3, 3),
       "lambda"=c(NA, 3, 3, 3, 3),
       "inv.phi"=2,
       "inv.psi"=c(2, 2, 2, 2, 2)),
  list("tau"=c(5, 5, 5, 5, 5),
       "lambda"=c(NA, 6, 6, 6, 6),
       "inv.phi"=.5,
       "inv.psi"=c(.5, .5, .5, .5, .5))
)

# vector of all parameters to save
# exclude fixed lambda since it throws an error in
# in the GRB plot
param_save <- c("tau", paste0("lambda[",2:5,"]"), "phi", "psi")

# fit model
fit <- jags(
  model.file=jags.model.cfa1,
  data=mydata,
  inits=start_values,
  parameters.to.save = param_save,
  n.iter=5000,
  n.burnin = 2500,
  n.chains = 3,
  n.thin=1,
  progress.bar = "none")

print(fit)

# extract posteriors for all chains
jags.mcmc <- as.mcmc(fit)

R2jags::traceplot(jags.mcmc)

# gelman-rubin-brook
gelman.plot(jags.mcmc)

# convert to single data.frame for density plot
a <- colnames(as.data.frame(jags.mcmc[[1]]))
plot.data <- data.frame(as.matrix(jags.mcmc, chains=T, iters = T))
colnames(plot.data) <- c("chain", "iter", a)


plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(
  plot.data,
  pars = c(paste0("tau[",1:5,"]")),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("lambda[", 2:5, "]")),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("psi[", 1:5, "]"), "phi"),
  prob = 0.8) +
  plot_title

```


## Stan - Single Latent Variable 

```{r chp9-cfa-fit-stan-1, warnings=T, message=T,error=T, cache=TRUE}

model_cfa1 <- '
data {
  int  N;
  int  J;
  matrix[N, J] X;
}

parameters {
  real ksi[N]; //latent variable values
  real tau[J]; //intercepts
  real load[J-1]; //factor loadings
  real<lower=0> psi[J]; //residual variance
  //real kappa; // factor means
  real<lower=0> phi; // factor variances
}

transformed parameters {
  real lambda[J];
  lambda[1] = 1;
  lambda[2:J] = load;
}

model {
  real kappa;
  kappa = 0;
  // likelihood for data
  for(i in 1:N){
    for(j in 1:J){
      X[i, j] ~ normal(tau[j] + ksi[i]*lambda[j], psi[j]);
    }
  }
  // prior for latent variable parameters
  ksi ~ normal(kappa, phi);
  
  phi ~ inv_gamma(5, 10);
  // prior for measurement model parameters
  tau ~ normal(3, 10);
  psi ~ inv_gamma(5, 10);

  for(j in 1:(J-1)){
    load[j] ~ normal(1, 10);
  }
  
}

'
# data must be in a list
dat <- read.table("code/CFA-One-Latent-Variable/Data/IIS.dat", header=T)

mydata <- list(
  N = 500, J = 5,
  X = as.matrix(dat)
)

# initial values
start_values <- list(
  list(tau = c(.1,.1,.1,.1,.1), lambda=c(0, 0, 0, 0, 0), phi = 1, psi=c(1, 1, 1, 1, 1)),
  list(tau = c(3,3,3,3,3), lambda=c(3, 3, 3, 3, 3), phi = 2, psi=c(.5, .5, .5, .5, .5)),
  list(tau = c(5, 5, 5, 5, 5), lambda=c(6, 6, 6, 6, 6), phi = 2, psi=c(2, 2, 2, 2, 2))
)

# Next, need to fit the model
#   I have explicitly outlined some common parameters
fit <- stan(
  model_code = model_cfa1, # model code to be compiled
  data = mydata,          # my data
  init = start_values,    # starting values
  chains = 3,             # number of Markov chains
  warmup = 1000,          # number of warm up iterations per chain
  iter = 5000,            # total number of iterations per chain
  cores = 1,              # number of cores (could use one per chain)
  refresh = 0             # no progress shown
)

# first get a basic breakdown of the posteriors
print(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"))

# plot the posterior in a
#  95% probability interval
#  and 80% to contrast the dispersion
plot(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"))

# traceplots
rstan::traceplot(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"), inc_warmup = TRUE)

# Gelman-Rubin-Brooks Convergence Criterion
ggs_grb(ggs(fit, family = c("lambda"))) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "phi")) +
   theme_bw() + theme(panel.grid = element_blank())
# autocorrelation
ggs_autocorrelation(ggs(fit, family="lambda")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="phi")) +
   theme_bw() + theme(panel.grid = element_blank())

# plot the posterior density
plot.data <- as.matrix(fit)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(
  plot.data,
  pars = paste0("lambda[",1:5,"]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = paste0("tau[",1:5,"]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("psi[",1:5,"]"),
           "phi"),
  prob = 0.8) +
  plot_title

# I prefer a posterior plot that includes prior and MLE
# Expanded Posterior Plot
colnames(dat) <- paste0("x",1:5)
lav.mod <- '
  xi =~ 1*x1 + x2 + x3 + x4 + x5
  xi ~~ xi
  x1 ~ 1
  x2 ~ 1
  x3 ~ 1
  x4 ~ 1
  x5 ~ 1
'
lav.fit <- lavaan::cfa(lav.mod, data=dat)

MLE <- lavaan::parameterEstimates(lav.fit)

prior_tau <- function(x){dnorm(x, 3, 10)}
x.tau<- seq(1, 5, 0.01)
prior.tau <- data.frame(tau=x.tau, dens.mtau = prior_tau(x.tau))

prior_lambda <- function(x){dnorm(x, 1, 10)}
x.lambda<- seq(0, 2, 0.01)
prior.lambda <- data.frame(lambda=x.lambda, dens.lambda = prior_lambda(x.lambda))

prior_sig <- function(x){dinvgamma(x, 5, 10)}
x.sig<- seq(.01, 1, 0.01)
prior.sig <- data.frame(sig=x.sig, dens.sig = prior_sig(x.sig))

prior_sige <- function(x){dinvgamma(x, 1, 4)}
x.sige<- seq(.1, 10, 0.1)
prior.sige <- data.frame(sige=x.sige, dens.sige = prior_sige(x.sige))

prior_ksi <- function(x){
  mu <- 0
  sig <- rinvgamma(1, 5, 10)
  rnorm(x, mu, sig)
}
x.ksi<- seq(-5, 5, 0.01)
prior.ksi <- data.frame(ksi=prior_ksi(10000))

cols <- c("Posterior"="#0072B2", "Prior"="#E69F00", "MLE"= "black")#"#56B4E9", "#E69F00" "#CC79A7"

# get stan samples
plot.data <- as.data.frame(plot.data)

# make plotting pieces
p1 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[1]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[1, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p2 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[2]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[2, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p3 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[3]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[3, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p4 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[4]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[4, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p5 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[5]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[5, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+theme_bw()+
  theme(panel.grid = element_blank())
p1 + p2 + p3 + p4 + p5 + plot_layout(guides="collect")


# phi
p1 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`phi`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[6,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())

# psi
p2 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[1]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[12,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p3 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[2]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[13,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p4 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[3]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[14,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p5 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[4]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[15,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p6 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[5]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[16,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())

p1 + p2 + p3 + p4 + p5 + p6 + plot_layout(guides = "collect")



```


## Blavaan - Single Latent Variable

```{r chp9-cfa-fit-blavaan-1, warnings=T, message=T, error=T, cache=TRUE}

# model
model_cfa_blavaan <- "
  f1 =~ 1*PI + AD + IGC + FI + FC
"

dat <- as.matrix(read.table("code/CFA-Two-Latent-Variables/Data/IIS.dat", header=T))

fit <- blavaan::bcfa(model_cfa_blavaan, data=dat)

summary(fit)
plot(fit)

```


## Two Latent Variable Model

Here we consider the model in section 9.4 which is a CFA model with 2 latent variables and 5 observed indicators.
The graphical representation of these factor models get pretty complex pretty quickly, but for this example I have reproduced a version of Figure 9.4, shown below.

```{r chp9-dag-2, echo=FALSE,fig.align='center',fig.cap='DAG for CFA model with 2 latent variables'}
knitr::include_graphics(paste0(w.d,'/dag/chp9-cfa2.png'),
                        auto_pdf = TRUE)
```

However, as the authors noted, the path diagram tradition of conveying models is also very useful in discussing and describing the model, which I give next.


```{r chp9-pathdiag-2, echo=FALSE,fig.align='center',fig.cap='Path Diagram for CFA model with 2 latent variables'}
knitr::include_graphics(paste0(w.d,'/path-diagram/chp9-cfa2.png'),
                        auto_pdf = TRUE)
```

For completeness, I have included the model specification diagram that more concretely connects the DAG and path diagram to the assumed distributions and priors.

```{r chp9-spec-2, echo=FALSE,fig.align='center',fig.cap='Model specification diagram for the CFA model with 2 latent factors'}
knitr::include_graphics(paste0(w.d,'/model-spec/chp9-cfa2.png'),
                        auto_pdf = TRUE)
```



## JAGS - Two Latent Variable

```{r chp9-cfa-fit-jags-2, warnings=T, message=T, error=T, cache=TRUE}

# model code
jags.model.cfa2 <- function(){

  ###################
  # Specify the factor analysis measurement model for the observables
  ####################
  for (i in 1:n){
    
    # expected value for each examinee for each observable
    mu[i,1] <- tau[1] + lambda[1,1]*ksi[i,1]  	
    mu[i,2] <- tau[2] + lambda[2,1]*ksi[i,1]     	
    mu[i,3] <- tau[3] + lambda[3,1]*ksi[i,1]          
    mu[i,4] <- tau[4] + lambda[4,2]*ksi[i,2]          
    mu[i,5] <- tau[5] + lambda[5,2]*ksi[i,2]          
    
    for(j in 1:J){
      x[i,j] ~ dnorm(mu[i,j], inv.psi[j])    # distribution for each observable
    }
  }
  
  
  ######################################################################
  # Specify the (prior) distribution for the latent variables
  ######################################################################
  for (i in 1:n){
    ksi[i, 1:M] ~ dmnorm(kappa[], inv.phi[,])  # distribution for the latent variables
  }
  
  
  ######################################################################
  # Specify the prior distribution for the parameters that govern the latent variables
  ######################################################################
  for(m in 1:M){
    kappa[m] <- 0              # Means of latent variables
  }
  
  inv.phi[1:M,1:M] ~ dwish(dxphi.0[ , ], d);  	# prior for precision matrix for the latent variables
  phi[1:M,1:M] <- inverse(inv.phi[ , ]);  		# the covariance matrix for the latent vars
  
  phi.0[1,1] <- 1;       			
  phi.0[1,2] <- .3;					
  phi.0[2,1] <- .3;
  phi.0[2,2] <- 1;
  d <- 2;							
                              
  for (m in 1:M){						
       for (mm in 1:M){
            dxphi.0[m,mm] <- d*phi.0[m,mm];
       }
  }
  
  
  
  ######################################################################
  # Specify the prior distribution for the measurement model parameters
  ######################################################################
  for(j in 1:J){
    tau[j] ~ dnorm(3, .1)        # Intercepts for observables
  	inv.psi[j] ~ dgamma(5, 10) # Precisions for observables
  	psi[j] <- 1/inv.psi[j]   # Variances for observables
  }
  
  lambda[1,1] <- 1.0              # loading fixed to 1.0 
  lambda[4,2] <- 1.0              # loading fixed to 1.0 
  
  for (j in 2:3){
  	lambda[j,1] ~ dnorm(1, .1)    # prior distribution for the remaining loadings
  }
  lambda[5,2] ~ dnorm(1, .1)      # prior distribution for the remaining loadings
}
# data must be in a list
dat <- read.table("code/CFA-One-Latent-Variable/Data/IIS.dat", header=T)

mydata <- list(
  n = 500, J = 5, M =2,
  x = as.matrix(dat)
)


# initial values
start_values <- list(
  list("tau"=c(1.00E-01, 1.00E-01, 1.00E-01, 1.00E-01, 1.00E-01),
       lambda= structure(
         .Data= c( NA,  2.00E+00, 2.00E+00, NA, NA,
                   NA,  NA,  NA,  NA, 2.00E+00),
         .Dim=c(5, 2)),
       inv.phi= structure(
         .Data= c(1.00E+00, 0.00E+00, 0.00E+00, 1.00E+00),
         .Dim=c(2, 2)),
       inv.psi=c(1.00E+00, 1.00E+00, 1.00E+00, 1.00E+00, 1.00E+00)),
  list(tau=c(3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00),
       lambda= structure(
         .Data= c( NA,  5.00E-01, 5.00E-01,  NA, NA, 
                   NA,  NA,  NA,  NA, 5.00E-01),
         .Dim=c(5, 2)),
       inv.phi= structure(
         .Data= c(1.33E+00, -6.67E-01, -6.67E-01, 1.33E+00),
         .Dim=c(2, 2)),
       inv.psi=c(2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00))
,
  list(tau=c(5.00E+00, 5.00E+00, 5.00E+00, 5.00E+00, 5.00E+00),
       lambda= structure(
         .Data= c( NA,  1.00E+00, 1.00E+00,  NA, NA,
                   NA,  NA,  NA,  NA, 1.00E+00),
         .Dim=c(5, 2)),
       inv.phi= structure(
         .Data= c(1.96E+00, -1.37E+00, -1.37E+00, 1.96E+00),
         .Dim=c(2, 2)),
       inv.psi=c(5.00E-01, 5.00E-01, 5.00E-01, 5.00E-01, 5.00E-01))
)

# vector of all parameters to save
# exclude fixed lambda since it throws an error in
# in the GRB plot
param_save <- c("tau", "lambda[2,1]","lambda[3,1]","lambda[5,2]", "phi", "psi")

# fit model
fit <- jags(
  model.file=jags.model.cfa2,
  data=mydata,
  inits=start_values,
  parameters.to.save = param_save,
  n.iter=5000,
  n.burnin = 2500,
  n.chains = 3,
  n.thin=1,
  progress.bar = "none")

print(fit)

# extract posteriors for all chains
jags.mcmc <- as.mcmc(fit)

R2jags::traceplot(jags.mcmc)

# gelman-rubin-brook
gelman.plot(jags.mcmc)

# convert to single data.frame for density plot
a <- colnames(as.data.frame(jags.mcmc[[1]]))
plot.data <- data.frame(as.matrix(jags.mcmc, chains=T, iters = T))
colnames(plot.data) <- c("chain", "iter", a)


plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(
  plot.data,
  pars = c(paste0("tau[",1:5,"]")),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c("lambda[2,1]","lambda[3,1]","lambda[5,2]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("psi[", 1:5, "]"), "phi"),
  prob = 0.8) +
  plot_title

```


## Stan - Two Latent Variable 

### Inverse-Wishart Prior

Using Stan based on a nearly identical model structure presented in the text.

```{r chp9-cfa-fit-stan-2, warnings=T, message=T,error=T, cache=TRUE}


model_cfa_2factor <- "
data {
  int  N;
  int  J;
  int  M;
  matrix[N, J] X;
  matrix[M, M] phi0;
}

parameters {
  matrix[M, M] phi; // latent variable covaraince matrix
  matrix[N, M] ksi; //latent variable values
  real lambda[J]; //factor loadings matrix
  real tau[J]; //intercepts
  real<lower=0> psi[J]; //residual variance
}

model {
  // likelihood for data
  for(i in 1:N){
    X[i, 1] ~ normal(tau[1] + ksi[i,1]*lambda[1], psi[1]);
    X[i, 2] ~ normal(tau[2] + ksi[i,1]*lambda[2], psi[2]);
    X[i, 3] ~ normal(tau[3] + ksi[i,1]*lambda[3], psi[3]);
    X[i, 4] ~ normal(tau[4] + ksi[i,2]*lambda[4], psi[4]);
    X[i, 5] ~ normal(tau[5] + ksi[i,2]*lambda[5], psi[5]);
    
    // prior for ksi
    ksi[i] ~ multi_normal(rep_vector(0, M), phi);
  }
  // latent variable variance matrix
  phi  ~ inv_wishart(2, phi0);
  // prior for measurement model parameters
  tau ~ normal(3, 10);
  psi ~ inv_gamma(5, 10);
  lambda[1] ~ normal(1, .001);
  lambda[2] ~ normal(1, 10);
  lambda[3] ~ normal(1, 10);
  lambda[4] ~ normal(1, .001);
  lambda[5] ~ normal(1, 10);
}

"

# data must be in a list
dat <- as.matrix(read.table("code/CFA-Two-Latent-Variables/Data/IIS.dat", header=T))

mydata <- list(
  N = 500, J = 5,
  M = 2,
  X = dat,
  phi0 = matrix(c(1, .3, .3, 1), ncol=2)
)

# # initial values
start_values <- list(
  list(
    phi= structure(
      .Data= c(1, 0.30, 0.30, 1),
      .Dim=c(2, 2)),
    tau = c(3, 3, 3, 3, 3),
    lambda= c(1, 1, 1, 1, 1),
    psi=c(.5, .5, .5, .5, .5)
  ),
  list(
    phi= structure(
      .Data= c(1, 0, 0, 1),
      .Dim=c(2, 2)),
    tau = c(5, 5, 5, 5, 5),
    lambda= c(1, .7, .7, 1, .7),
    psi=c(2, 2, 2, 2, 2)
  ),
  list(
    phi= structure(
      .Data= c(1, 0.10, 0.10, 1),
      .Dim=c(2, 2)),
    tau = c(1, 1, 1, 1, 1),
    lambda= c(1, 1.3, 1.3, 1, 1.3),
    psi=c(1, 1, 1, 1, 1)
  )
)

# Next, need to fit the model
#   I have explicitly outlined some common parameters
fit <- stan(
  model_code = model_cfa_2factor, # model code to be compiled
  data = mydata,          # my data
  init = start_values,    # starting values
  refresh = 0             # no progress shown
)
# first get a basic breakdown of the posteriors
print(fit, 
      pars =c("lambda", "tau", "psi",
              "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"))

# plot the posterior in a
#  95% probability interval
#  and 80% to contrast the dispersion
plot(fit,
     pars =c("lambda", "tau", "psi",
              "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"))

# traceplots
rstan::traceplot(
  fit,
  pars =c("lambda", "tau", "psi",
              "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"),
  inc_warmup = TRUE)

# Gelman-Rubin-Brooks Convergence Criterion
ggs_grb(ggs(fit, family = c("lambda"))) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "phi")) +
   theme_bw() + theme(panel.grid = element_blank())
# autocorrelation
ggs_autocorrelation(ggs(fit, family="lambda")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="phi")) +
   theme_bw() + theme(panel.grid = element_blank())

```


### LKJ Cholesky Parameterization

Because I had such massive problems with the above, I search for how people estimate CFA models in Stan.
I found that most people use the LKJ Cholesky parameterization.

Some helpful pages that I used to help get this to work.

* [Stan User's Guide on Factor Covaraince Parameterization](https://mc-stan.org/docs/2_24/stan-users-guide/loading-matrix-for-factor-analysis.html)
* [Michael DeWitt - Confirmatory Factor Analysis in Stan](https://michaeldewittjr.com/resources/stan_cfa.html#bayesian_version)
* [Rick Farouni - Fitting a Bayesian Factor Analysis Model in Stan](https://rfarouni.github.io/assets/projects/BayesianFactorAnalysis/BayesianFactorAnalysis.html)

```{r chp9-cfa-fit-stan-3, warnings=T, message=T,error=T, cache=TRUE}


model_cfa2 <- "
data {
  int  N;
  int  J;
  int  M;
  matrix[N, J] X;
}

parameters {
  cholesky_factor_corr[M] L; // Cholesky decomp of 
                              // corr mat of random slopes
  vector[M] A; // Vector of factor variances
  matrix[N, M] ksi; //latent variable values
  vector[J] lambda; //factor loadings matrix
  real tau[J]; //intercepts
  real<lower=0> psi[J]; //residual variance
}

transformed parameters {
  matrix[M, M] A0;
  vector[M] S;
  A0 = diag_pre_multiply(A, L);
  S = sqrt(A);
}

model {
  
  // likelihood for data
  for(i in 1:N){
    X[i, 1] ~ normal(tau[1] + ksi[i,1]*lambda[1], psi[1]);
    X[i, 2] ~ normal(tau[2] + ksi[i,1]*lambda[2], psi[2]);
    X[i, 3] ~ normal(tau[3] + ksi[i,1]*lambda[3], psi[3]);
    X[i, 4] ~ normal(tau[4] + ksi[i,2]*lambda[4], psi[4]);
    X[i, 5] ~ normal(tau[5] + ksi[i,2]*lambda[5], psi[5]);
  }
  // latent variable parameters
  A ~ inv_gamma(5, 10);
  L ~ lkj_corr_cholesky(M);
  for(i in 1:N){
    ksi[i] ~ multi_normal_cholesky(rep_vector(0, M), A0);
  }
  // prior for measurement model parameters
  tau ~ normal(3, 10);
  psi ~ inv_gamma(5, 10);
  // factor loading patterns
  lambda[1] ~ normal(1, .001);
  lambda[2] ~ normal(1, 10);
  lambda[3] ~ normal(1, 10);
  lambda[4] ~ normal(1, .001);
  lambda[5] ~ normal(1, 10);
}

generated quantities {
  matrix[M, M] R;
  matrix[M, M] phi;
  
  R = tcrossprod(L);
  phi = quad_form_diag(R, S);
}

"

# data must be in a list
dat <- as.matrix(read.table("code/CFA-Two-Latent-Variables/Data/IIS.dat", header=T))

mydata <- list(
  N = 500, J = 5,
  M = 2,
  X = dat
)

# Next, need to fit the model
#   I have explicitly outlined some common parameters
fit <- stan(
  model_code = model_cfa2, # model code to be compiled
  data = mydata,          # my data
  #init = init_fun, #start_values,    # starting values
  refresh = 0             # no progress shown
)

# first get a basic breakdown of the posteriors
print(fit, 
      pars =c("lambda", "tau", "psi",
              "R", "A", "A0", "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"))

# plot the posterior in a
#  95% probability interval
#  and 80% to contrast the dispersion
plot(fit,pars =c("lambda", "tau", "psi",
                 "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"))

# traceplots
rstan::traceplot(fit,
      pars =c("lambda", "tau", "psi",
              "phi",
              "ksi[1, 1]", "ksi[1, 2]",
              "ksi[8, 1]", "ksi[8, 2]"), inc_warmup = TRUE)

# Gelman-Rubin-Brooks Convergence Criterion
ggs_grb(ggs(fit, family = c("lambda"))) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "phi")) +
   theme_bw() + theme(panel.grid = element_blank())
# autocorrelation
ggs_autocorrelation(ggs(fit, family="lambda")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="phi")) +
   theme_bw() + theme(panel.grid = element_blank())

# plot the posterior density
plot.data <- as.matrix(fit)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(
  plot.data,
  pars = c("lambda[2]", "lambda[3]", "lambda[5]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = paste0("tau[",1:5,"]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("psi[",1:5,"]"),
           "phi[1,1]", "phi[1,2]", "phi[2,2]"),
  prob = 0.8) +
  plot_title

```

## Blavaan - Two Latent Variables


```{r chp9-cfa-fit-blavaan-2, warnings=T, message=T,error=T, cache=TRUE}

# model
model_cfa2_blavaan <- "
  f1 =~ 1*PI + AD + IGC 
  f2 =~ 1*FI + FC
  f1 ~~ f2
"

dat <- as.matrix(read.table("code/CFA-Two-Latent-Variables/Data/IIS.dat", header=T))

fit <- blavaan::bcfa(model_cfa2_blavaan, data=dat)

summary(fit)

plot(fit)


```

## Indeterminacy in One Factor CFA

```{r chp9-cfa-fit-jags-FID, warnings=T, message=T,error=T, cache=TRUE}


# model code
jags.model.cfa.ind <- function(){

  ######################################################################
  # Specify the factor analysis measurement model for the observables
  ######################################################################
  for (i in 1:n){
    for(j in 1:J){
      mu[i,j] <- tau[j] + ksi[i]*lambda[j]      # model implied expectation for each observable
      x[i,j] ~ dnorm(mu[i,j], inv.psi[j])    # distribution for each observable
    }
  }
  
  
  ######################################################################
  # Specify the (prior) distribution for the latent variables
  ######################################################################
  for (i in 1:n){
    ksi[i] ~ dnorm(kappa, inv.phi)  # distribution for the latent variables
  }
  
  
  ######################################################################
  # Specify the prior distribution for the parameters that govern the latent variables
  ######################################################################
  kappa <- 0              # Mean of factor 1
  inv.phi <-1  	# Precision of factor 1
  phi <- 1/inv.phi        # Variance of factor 1
  
  
  ######################################################################
  # Specify the prior distribution for the measurement model parameters
  ######################################################################
  for(j in 1:J){
    tau[j] ~ dnorm(3, .1)        # Intercepts for observables
  	inv.psi[j] ~ dgamma(5, 10) # Precisions for observables
  	psi[j] <- 1/inv.psi[j]   # Variances for observables
  }
  
  for (j in 1:J){
  	lambda[j] ~ dnorm(1, .1)    # prior distribution for the remaining loadings
  }
}
# data must be in a list
dat <- read.table("code/CFA-One-Latent-Variable/Data/IIS.dat", header=T)

mydata <- list(
  n = 500, J = 5,
  x = as.matrix(dat)
)


# initial values
start_values <- list(
  list("tau"=c(3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00),
       "lambda"=c(3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00),
       "inv.psi"=c(2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00)),
  list("tau"=c(3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00, 3.00E+00),
       "lambda"=c(-3.00E+00, -3.00E+00, -3.00E+00, -3.00E+00, -3.00E+00),
       "inv.psi"=c(2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00, 2.00E+00))
)

# vector of all parameters to save
# exclude fixed lambda since it throws an error in
# in the GRB plot
param_save <- c("tau[1]", "lambda[1]", "phi", "psi[1]", "ksi[8]")

# fit model
fit <- jags(
  model.file=jags.model.cfa.ind,
  data=mydata,
  inits=start_values,
  parameters.to.save = param_save,
  n.iter=5000,
  n.burnin = 2500,
  n.chains = 2,
  n.thin=1,
  progress.bar = "none")

print(fit)

# extract posteriors for all chains
jags.mcmc <- as.mcmc(fit)

R2jags::traceplot(jags.mcmc)


```
