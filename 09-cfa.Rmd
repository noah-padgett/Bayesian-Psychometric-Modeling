# Confirmatory Factor Analysis

The full Bayesian specification of a _general_ CFA model for all associated unknowns is as follows.
This includes probability statements, notation, parameters, likelihood, priors, and hyperparameters.
The observed data is defined as the $n\times J$ matrix $\mathbf{X}$ for the $J$ observed measures.
The CFA model parameters are defined as

\begin{align*}
\mathbf{x}_i &= \tau + \Lambda\xi_i + \varepsilon_i\\
\Sigma (\mathbf{x}) &= \Lambda\Phi\Lambda^{\prime} + \Psi
\end{align*}


* $\Xi$ is the $n\times M$ matrix of latent variable scores on the $M$ latent variables for the $n$ respondents/subjects. For an single subject, $\xi_i$ represents the vector of scores on the latent variable(s). Values (location, scale, orientation, etc.) or $\xi_i$ are conditional on (1) $\kappa$, the $M\times 1$ vector of latent variable means, and (2) $\Phi$, the $M\times M$ covariance matrix of variable variables;
* $\tau$ is the $J\times 1$ vector of observed variable intercepts which is the expected value for the observed measures when the latent variable(s) are all $0$;
* $\Lambda$ is the $J\times M$ matrix of factor loadings where the $j$th row and $m$th column represents the factor loading of the $j$th observed variable on the $m$th latent variable;
* $\delta_i$ is the $J\times 1$ vector of errors, where $E(\delta_i)=\mathbf{0}$ with $\mathrm{var}(\delta_i)=\Psi$ which is the $J\times J$ error covariance matrix.

\begin{align*}
p(\Xi, \kappa, \Phi, \tau, \Lambda, \Psi\mid \mathbf{X}) &\propto p(\mathbf{X}\mid\Xi, \kappa, \Phi, \tau, \Lambda, \Psi)p(\Xi, \kappa, \Phi, \tau, \Lambda, \Psi)\\
  &= p(\mathbf{X}\mid\Xi, \kappa, \Phi, \tau, \Lambda, \Psi) p(\Xi\mid\kappa, \Phi) p(\kappa) p(\Phi) p(\tau) p(\Lambda) p(\Psi)\\
  &= \prod_{i=1}^{n}\prod_{j=1}^J\prod_{m=1}^M p(x_{ij}\mid\xi_i, \tau_j,\lambda_j, \psi_{jj}) p(\xi_i\mid\kappa, \Phi) p(\kappa_m) p(\Phi) p(\tau_j) p(\lambda_j) p(\psi_{jj})
\end{align*}
where

\begin{align*}
x_{ij}\mid\xi_i, \tau_j,\lambda_j, \psi_{jj} &\sim \mathrm{Normal}(\tau_j+\xi_i\lambda^{\prime}_j, \psi_{jj}),\ \mathrm{for}\ i=1, \cdots, n,\ j = 1, \cdots, J;\\
\xi_i\mid\kappa, \Phi &\sim \mathrm{Normal}(\kappa, \Phi),\ \mathrm{for}\ i=1, \cdots, n;\\
\kappa_m &\sim \mathrm{Normal}(\mu_{\kappa},\sigma^2_{\kappa}),\ \mathrm{for}\ m = 1, \cdots, M;\\
\Phi &\sim \mathrm{Inverse-Wishart}(\Phi_0, d);\\
\tau_j &\sim \mathrm{Normal}(\mu_{\tau},\sigma^2_{\tau}),\ \mathrm{for}\ j = 1, \cdots, J;\\
\lambda_{j,m} &\sim \mathrm{Normal}(\mu_{\lambda}, \sigma^2_{\lambda}),\ \mathrm{for}\ j = 1, \cdots, J,\ m = 1, \cdots, M;\\
\psi_{jj} &\sim \mathrm{Inverse-Gamma}(\nu_{\psi}/2, \nu_{\psi}\psi_0/2),\ \mathrm{for}\ j=1, \cdots, J.
\end{align*}
With the hyperparameters that are supplied by the analyst being defined as

* $\mu_{\kappa}$ is the prior mean for the latent variable,
* $\sigma^2_{\kappa}$ is the prior variance for the latent variable,
* $\Phi_0$ is the prior expectation for the covariance matrix among latent variables,
* $d$ represents a dispersion parameter reflecting the magnitude of our beliefs about $\Phi_0$,
* $\mu_{\tau}$ is the prior mean for the intercepts which reflects our knowledge about the location of the observed variables,
* $\sigma^2_{\tau}$ is a measure of how much weight we want to give to the prior mean,
* $\mu_{\lambda}$ is the prior mean for the factor loadings which can vary over items and latent variables,
* $\sigma^2_{\lambda}$ is the measure of dispersion for the the factor loadings, where lower variances indicate a stronger belief about the values for the loadings,
* $\nu_{\psi}$ is the measure of location for the gamma prior indicating our expectation for the magnitude of the error variance,
* $\psi_0$ is our uncertainty with respect to the location we selected for the variance, and
* Alternatively, we could place a prior on $\Psi$ instead of the individual residual variances. This would mean we would be placing a prior on the error-covariance matrix similar to how we specified a prior for latent variance covariance matrix.


## Single Latent Variable Model

Here we consider the model in section 9.3 which is a CFA model with 1 latent variable and 5 observed indicators.
The graphical representation of these factor models get pretty complex pretty quickly, but for this example I have reproduced a version of Figure 9.3b, shown below.

```{r chp9-dag-1, echo=FALSE,fig.align='center',fig.cap='DAG for CFA model with 1 latent variable'}
knitr::include_graphics(paste0(w.d,'/dag/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```

However, as the authors noted, the path diagram tradition of conveying models is also very useful in discussing and describing the model, which I give next.


```{r chp9-pathdiag-1, echo=FALSE,fig.align='center',fig.cap='DAG for CFA model with 1 latent variable'}
knitr::include_graphics(paste0(w.d,'/path-diagram/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```

For completeness, I have included the model specification diagram that more concretely connects the DAG and path diagram to the assumed distributions and priors.

```{r chp9-spec-1, echo=FALSE,fig.align='center',fig.cap='Model specification diagram for the CFA model with 1 latent factor'}
knitr::include_graphics(paste0(w.d,'/model-spec/chp9-cfa1.png'),
                        auto_pdf = TRUE)
```

## Stan - Single Latent Variable 

```{r chp9-cfa-fit-stan-1, warnings=T, message=T,error=T, cache=TRUE}

model_cfa1 <- '
data {
  int  N;
  int  J;
  matrix[N, J] X;
}

parameters {
  real ksi[N]; //latent variable values
  real tau[J]; //intercepts
  real load[J-1]; //factor loadings
  real<lower=0> psi[J]; //residual variance
  //real kappa; // factor means
  real<lower=0> phi; // factor variances
}

transformed parameters {
  real lambda[J];
  lambda[1] = 1;
  lambda[2:J] = load;
}

model {
  real kappa;
  kappa = 0;
  // likelihood for data
  for(i in 1:N){
    for(j in 1:J){
      X[i, j] ~ normal(tau[j] + ksi[i]*lambda[j], psi[j]);
    }
  }
  // prior for latent variable parameters
  ksi ~ normal(kappa, phi);
  
  phi ~ inv_gamma(5, 10);
  // prior for measurement model parameters
  tau ~ normal(3, 10);
  psi ~ inv_gamma(5, 10);

  for(j in 1:(J-1)){
    load[j] ~ normal(1, 10);
  }
  
}

'
# data must be in a list
dat <- read.table("code/CFA-One-Latent-Variable/Data/IIS.dat", header=T)

mydata <- list(
  N = 500, J = 5,
  X = as.matrix(dat)
)

# initial values
start_values <- list(
  list(tau = c(.1,.1,.1,.1,.1), lambda=c(0, 0, 0, 0, 0), phi = 1, psi=c(1, 1, 1, 1, 1)),
  list(tau = c(3,3,3,3,3), lambda=c(3, 3, 3, 3, 3), phi = 2, psi=c(.5, .5, .5, .5, .5)),
  list(tau = c(5, 5, 5, 5, 5), lambda=c(6, 6, 6, 6, 6), phi = 2, psi=c(2, 2, 2, 2, 2))
)

# Next, need to fit the model
#   I have explicitly outlined some common parameters
fit <- stan(
  model_code = model_cfa1, # model code to be compiled
  data = mydata,          # my data
  init = start_values,    # starting values
  chains = 3,             # number of Markov chains
  warmup = 1000,          # number of warm up iterations per chain
  iter = 5000,            # total number of iterations per chain
  cores = 1,              # number of cores (could use one per chain)
  refresh = 0             # no progress shown
)

# first get a basic breakdown of the posteriors
print(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"))

# plot the posterior in a
#  95% probability interval
#  and 80% to contrast the dispersion
plot(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"))

# traceplots
rstan::traceplot(fit,pars =c("lambda", "tau", "psi", "phi", "ksi[1]", "ksi[8]"), inc_warmup = TRUE)

# Gelman-Rubin-Brooks Convergence Criterion
ggs_grb(ggs(fit, family = c("lambda"))) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_grb(ggs(fit, family = "phi")) +
   theme_bw() + theme(panel.grid = element_blank())
# autocorrelation
ggs_autocorrelation(ggs(fit, family="lambda")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="tau")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="psi")) +
   theme_bw() + theme(panel.grid = element_blank())
ggs_autocorrelation(ggs(fit, family="phi")) +
   theme_bw() + theme(panel.grid = element_blank())

# plot the posterior density
plot.data <- as.matrix(fit)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(
  plot.data,
  pars = paste0("lambda[",1:5,"]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = paste0("tau[",1:5,"]"),
  prob = 0.8) +
  plot_title

mcmc_areas(
  plot.data,
  pars = c(paste0("psi[",1:5,"]"),
           "phi"),
  prob = 0.8) +
  plot_title

# I prefer a posterior plot that includes prior and MLE
# Expanded Posterior Plot
colnames(dat) <- paste0("x",1:5)
lav.mod <- '
  xi =~ 1*x1 + x2 + x3 + x4 + x5
  xi ~~ xi
  x1 ~ 1
  x2 ~ 1
  x3 ~ 1
  x4 ~ 1
  x5 ~ 1
'
lav.fit <- lavaan::cfa(lav.mod, data=dat)

MLE <- lavaan::parameterEstimates(lav.fit)

prior_tau <- function(x){dnorm(x, 3, 10)}
x.tau<- seq(1, 5, 0.01)
prior.tau <- data.frame(tau=x.tau, dens.mtau = prior_tau(x.tau))

prior_lambda <- function(x){dnorm(x, 1, 10)}
x.lambda<- seq(0, 2, 0.01)
prior.lambda <- data.frame(lambda=x.lambda, dens.lambda = prior_lambda(x.lambda))

prior_sig <- function(x){dinvgamma(x, 5, 10)}
x.sig<- seq(.01, 1, 0.01)
prior.sig <- data.frame(sig=x.sig, dens.sig = prior_sig(x.sig))

prior_sige <- function(x){dinvgamma(x, 1, 4)}
x.sige<- seq(.1, 10, 0.1)
prior.sige <- data.frame(sige=x.sige, dens.sige = prior_sige(x.sige))

prior_ksi <- function(x){
  mu <- 0
  sig <- rinvgamma(1, 5, 10)
  rnorm(x, mu, sig)
}
x.ksi<- seq(-5, 5, 0.01)
prior.ksi <- data.frame(ksi=prior_ksi(10000))

cols <- c("Posterior"="#0072B2", "Prior"="#E69F00", "MLE"= "black")#"#56B4E9", "#E69F00" "#CC79A7"

# get stan samples
plot.data <- as.data.frame(plot.data)

# make plotting pieces
p1 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[1]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[1, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p2 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[2]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[2, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p3 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[3]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[3, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p4 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[4]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[4, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+
  theme_bw()+
  theme(panel.grid = element_blank())
p5 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`lambda[5]`, color="Posterior"))+
  geom_line(data=prior.lambda,
            aes(x=lambda, y=dens.lambda, color="Prior"))+
  geom_vline(aes(xintercept=MLE[5, 4], color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  lims(x=c(0.25, 1.5))+theme_bw()+
  theme(panel.grid = element_blank())
p1 + p2 + p3 + p4 + p5 + plot_layout(guides="collect")


# phi
p1 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`phi`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[6,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())

# psi
p2 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[1]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[12,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p3 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[2]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[13,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p4 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[3]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[14,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p5 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[4]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[15,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())
p6 <- ggplot()+
  geom_density(data=plot.data,
               aes(x=`psi[5]`, color="Posterior"))+
  geom_line(data=prior.sig,
            aes(x=sig, y=dens.sig, color="Prior"))+
  geom_vline(aes(xintercept=sqrt(MLE[16,4]), color="MLE"))+
  scale_color_manual(values=cols, name=NULL)+
  theme_bw()+
  theme(panel.grid = element_blank())

p1 + p2 + p3 + p4 + p5 + p6 + plot_layout(guides = "collect")



```

<!-- ## Example 2 - JAGS -->

<!-- ```{r chp8-ctt-fit-jags-2, warnings=T, message=T, error=T, cache=TRUE} -->

<!-- # model code -->
<!-- jags.model.ctt2 <- function(){ -->
<!--    ############################################ -->
<!--      # CLASSICAL TEST THEORY -->
<!--      # WITH KNOWN  -->
<!--      #    TRUE SCORE MEAN, TRUE SCORE VARIANCE -->
<!--      #    ERROR VARIANCE -->
<!--      ############################################ -->

<!--      ############################################ -->
<!--      # KNOWN HYPERPARAMETERS -->
<!--      ############################################ -->
<!--      mu.T <- 80               # Mean of the true scores -->
<!--      sigma.squared.T <- 36    # Variance of the true scores -->
<!--      sigma.squared.E <- 16    # Variance of the errors -->

<!--      tau.T <- 1/sigma.squared.T   # Precision of the true scores -->
<!--      tau.E <- 1/sigma.squared.E   # Precision of the errors -->


<!--      ############################################ -->
<!--      # MODEL FOR TRUE SCORES AND OBSERVABLES -->
<!--      ############################################ -->

<!--      for (i in 1:N) { -->
<!--         T[i] ~ dnorm(mu.T, tau.T)     # Distribution of true scores -->
<!--         for(j in 1:J){ -->
<!--           x[i, j] ~ dnorm(T[i], tau.E)     # Distribution of observables  -->
<!--         } -->
<!--      } -->

<!-- } -->
<!-- # data -->
<!-- mydata <- list( -->
<!--   N = 10, J = 5,  -->
<!--   x = matrix( -->
<!--     c(80, 77, 80, 73, 73, -->
<!--       83, 79, 78, 78, 77, -->
<!--       85, 77, 88, 81, 80, -->
<!--       76, 76, 76, 78, 67, -->
<!--       70, 69, 73, 71, 77, -->
<!--       87, 89, 92, 91, 87, -->
<!--       76, 75, 79, 80, 75, -->
<!--       86, 75, 80, 80, 82, -->
<!--       84, 79, 79, 77, 82, -->
<!--       96, 85, 91, 87, 90), -->
<!--     ncol=5, nrow=10, byrow=T) -->
<!-- ) -->

<!-- # starting values -->
<!-- start_values <- function(){ -->
<!--   list("T"=rep(80,10)) -->
<!-- } -->

<!-- # vector of all parameters to save -->
<!-- param_save <- c("T") -->

<!-- # fit model -->
<!-- fit <- jags( -->
<!--   model.file=jags.model.ctt2, -->
<!--   data=mydata, -->
<!--   inits=start_values, -->
<!--   parameters.to.save = param_save, -->
<!--   n.iter=4000, -->
<!--   n.burnin = 1000, -->
<!--   n.chains = 4, -->
<!--   n.thin=1, -->
<!--   progress.bar = "none") -->

<!-- print(fit) -->

<!-- # extract posteriors for all chains -->
<!-- jags.mcmc <- as.mcmc(fit) -->

<!-- R2jags::traceplot(jags.mcmc) -->

<!-- # gelman-rubin-brook -->
<!-- gelman.plot(jags.mcmc) -->

<!-- # convert to single data.frame for density plot -->
<!-- a <- colnames(as.data.frame(jags.mcmc[[1]])) -->
<!-- plot.data <- data.frame(as.matrix(jags.mcmc, chains=T, iters = T)) -->
<!-- colnames(plot.data) <- c("chain", "iter", a) -->


<!-- plot_title <- ggtitle("Posterior distributions", -->
<!--                       "with medians and 80% intervals") -->
<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c("T[1]", "T[2]", "T[3]"), -->
<!--   prob = 0.8) +  -->
<!--   plot_title -->

<!-- # I prefer a posterior plot that includes prior and MLE -->
<!-- MLE <- rowMeans(mydata$X) -->
<!-- prior_t <- function(x){dnorm(x, 80, 6)} -->
<!-- x.t<- seq(50.1, 100, 0.1) -->
<!-- prior.t <- data.frame(tr=x.t, dens.t = prior_t(x.t)) -->
<!-- cols <- c("Posterior"="#0072B2", "Prior"="#E69F00", "MLE"= "black")#"#56B4E9", "#E69F00" "#CC79A7" -->

<!-- p1 <- ggplot()+ -->
<!--   geom_density(data=plot.data, -->
<!--                aes(x=`T[1]`, color="Posterior"))+ -->
<!--   geom_line(data=prior.t, -->
<!--             aes(x=tr, y=dens.t, color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[1], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p2 <- ggplot()+ -->
<!--   geom_density(data=plot.data, -->
<!--                aes(x=`T[2]`, color="Posterior"))+ -->
<!--   geom_line(data=prior.t, -->
<!--             aes(x=tr, y=dens.t, color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[2], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p3 <- ggplot()+ -->
<!--   geom_density(data=plot.data, -->
<!--                aes(x=`T[5]`, color="Posterior"))+ -->
<!--   geom_line(data=prior.t, -->
<!--             aes(x=tr, y=dens.t, color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[5], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p3 <- ggplot()+ -->
<!--   geom_density(data=plot.data, -->
<!--                aes(x=`T[10]`, color="Posterior"))+ -->
<!--   geom_line(data=prior.t, -->
<!--             aes(x=tr, y=dens.t, color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[10], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p1 + p2 + p3 + plot_layout(guides="collect") -->

<!-- ``` -->

<!-- ## Example 3 - Unknown Measurement Model with Multiple Measures -->

<!-- Here, we finally get to the (more) realistic case when we don't have as much prior knowledge about the measurement model parameters (namely, variances). -->
<!-- The structure relies on hierarchically specifying priors to induce conditional independence. -->
<!-- The DAG and model-specification change to: -->

<!-- ```{r chp8-dag-3, echo=FALSE,fig.align='center',fig.cap='Simple CTT model with unknown measurement parameters'} -->
<!-- knitr::include_graphics(paste0(w.d,'/dag/chp8-ctt3.png'), -->
<!--                         auto_pdf = TRUE) -->
<!-- ``` -->


<!-- ```{r chp8-spec-3, echo=FALSE,fig.align='center',fig.cap='Model specification diagram for the unknown measurement model parameters'} -->
<!-- knitr::include_graphics(paste0(w.d,'/model-spec/chp8-ctt3.png'), -->
<!--                         auto_pdf = TRUE) -->
<!-- ``` -->

<!-- ## Example 3 - Stan -->

<!-- ```{r chp8-ctt-fit-stan-3, warnings=T, message=T,error=T, cache=TRUE} -->

<!-- model_ctt3 <- ' -->
<!-- data { -->
<!--   int  N; -->
<!--   int  J; -->
<!--   matrix[N, J] X; -->
<!-- } -->

<!-- parameters { -->
<!--   real T[N]; -->
<!--   real muT; -->
<!--   real<lower=0> sigmaT; -->
<!--   real<lower=0> sigmaE; -->
<!-- } -->

<!-- model { -->
<!--   for(i in 1:N){ -->
<!--     T[i] ~ normal(muT, sigmaT); -->
<!--     for(j in 1:J){ -->
<!--       X[i, j] ~ normal(T[i], sigmaE); -->
<!--     } -->
<!--   } -->
<!--   muT ~ normal(80, 10); -->
<!--   sigmaT ~ inv_gamma(1, 6); -->
<!--   sigmaE ~ inv_gamma(1, 4); -->
<!-- } -->

<!-- generated quantities { -->
<!--   real rho; -->
<!--   real rhocomp; -->

<!--   rho = square(sigmaT)/(square(sigmaT) + square(sigmaE)); -->
<!--   rhocomp = J*rho/((J-1)*rho + 1); -->
<!-- } -->

<!-- ' -->
<!-- # data must be in a list -->
<!-- mydata <- list( -->
<!--   N = 10, J = 5, -->
<!--   X = matrix( -->
<!--     c(80, 77, 80, 73, 73, -->
<!--       83, 79, 78, 78, 77, -->
<!--       85, 77, 88, 81, 80, -->
<!--       76, 76, 76, 78, 67, -->
<!--       70, 69, 73, 71, 77, -->
<!--       87, 89, 92, 91, 87, -->
<!--       76, 75, 79, 80, 75, -->
<!--       86, 75, 80, 80, 82, -->
<!--       84, 79, 79, 77, 82, -->
<!--       96, 85, 91, 87, 90), -->
<!--     ncol=5, nrow=10, byrow=T) -->
<!-- ) -->

<!-- # initial values -->
<!-- start_values <- function(){ -->
<!--   list(T=c(80,80,80,80,80,80,80,80,80,80), -->
<!--        muT=80, sigmaT=10, sigmaE=5) -->
<!-- } -->

<!-- # Next, need to fit the model -->
<!-- #   I have explicitly outlined some common parameters -->
<!-- fit <- stan( -->
<!--   model_code = model_ctt3, # model code to be compiled -->
<!--   data = mydata,          # my data -->
<!--   init = start_values,    # starting values -->
<!--   chains = 4,             # number of Markov chains -->
<!--   warmup = 1000,          # number of warm up iterations per chain -->
<!--   iter = 5000,            # total number of iterations per chain -->
<!--   cores = 4,              # number of cores (could use one per chain) -->
<!--   refresh = 0             # no progress shown -->
<!-- ) -->

<!-- # first get a basic breakdown of the posteriors -->
<!-- print(fit) -->

<!-- # plot the posterior in a -->
<!-- #  95% probability interval -->
<!-- #  and 80% to contrast the dispersion -->
<!-- plot(fit) -->

<!-- # traceplots -->
<!-- rstan::traceplot(fit, pars = c("T", "muT", "sigmaT", "sigmaE", "rho", "rhocomp"), inc_warmup = TRUE) -->

<!-- # Gelman-Rubin-Brooks Convergence Criterion -->
<!-- p1 <- ggs_grb(ggs(fit)) + -->
<!--    theme_bw() + theme(panel.grid = element_blank()) -->
<!-- p1 -->
<!-- # autocorrelation -->
<!-- p1 <- ggs_autocorrelation(ggs(fit)) + -->
<!--    theme_bw() + theme(panel.grid = element_blank()) -->
<!-- p1 -->
<!-- # plot the posterior density -->
<!-- plot.data <- as.matrix(fit) -->

<!-- plot_title <- ggtitle("Posterior distributions", -->
<!--                       "with medians and 80% intervals") -->
<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c(paste0("T[",1:10,"]"), "muT"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->

<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c("sigmaT", "sigmaE"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->

<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c("rho", "rhocomp"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->
<!-- # I prefer a posterior plot that includes prior and MLE -->
<!-- # Expanded Posterior Plot -->
<!-- MLE <- c(rowMeans(mydata$X), mean(mydata$X)) -->

<!-- prior_mu <- function(x){dnorm(x, 80, 10)} -->
<!-- x.mu<- seq(50.1, 100, 0.1) -->
<!-- prior.mu <- data.frame(mu=x.mu, dens.mu = prior_mu(x.mu)) -->

<!-- prior_sigt <- function(x){dinvgamma(x, 1, 6)} -->
<!-- x.sigt<- seq(.1, 15, 0.1) -->
<!-- prior.sigt <- data.frame(sigt=x.sigt, dens.sigt = prior_sigt(x.sigt)) -->

<!-- prior_sige <- function(x){dinvgamma(x, 1, 4)} -->
<!-- x.sige<- seq(.1, 10, 0.1) -->
<!-- prior.sige <- data.frame(sige=x.sige, dens.sige = prior_sige(x.sige)) -->

<!-- prior_t <- function(x){ -->
<!--   mu <- rnorm(1, 80, 10) -->
<!--   sig <- rinvgamma(1, 1, 4) -->
<!--   rnorm(x, mu, sig) -->
<!-- } -->
<!-- x.t<- seq(50.1, 100, 0.1) -->
<!-- prior.t <- data.frame(tr=prior_t(10000)) -->


<!-- cols <- c("Posterior"="#0072B2", "Prior"="#E69F00", "MLE"= "black")#"#56B4E9", "#E69F00" "#CC79A7" -->
<!-- plot.data <- as.data.frame(plot.data) -->
<!-- p1 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[1]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[1], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p2 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[5]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[5], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p3 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[10]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[10], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p4 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`muT`, color="Posterior"))+ -->
<!--   geom_line(data=prior.mu,aes(x=mu,y=dens.mu,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[11], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p5 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`sigmaT`, color="Posterior"))+ -->
<!--   geom_line(data=prior.sigt,aes(x=sigt,y=dens.sigt,color="Prior"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p6 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`sigmaE`, color="Posterior"))+ -->
<!--   geom_line(data=prior.sige,aes(x=sige,y=dens.sige,color="Prior"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p1 + p2 + p3 + p4 + p5 + p6 + plot_layout(ncol=3, guides="collect") -->


<!-- ``` -->

<!-- ## Example 3 - JAGS -->

<!-- ```{r chp8-ctt-fit-jags-3, warnings=T, message=T, error=T, cache=TRUE} -->

<!-- # model code -->
<!-- jags.model.ctt3 <- function(){ -->
<!--      ############################################ -->
<!--      # CLASSICAL TEST THEORY MODEL -->
<!--      # WITH UnkNOWN HYPERPARAMETERS -->
<!--      #    TRUE SCORE MEAN, TRUE SCORE VARIANCE -->
<!--      #    ERROR VARIANCE -->
<!--      ############################################ -->

<!--      ############################################ -->
<!--      # PRIOR DISTRIBUTIONS FOR HYPERPARAMETERS -->
<!--      ############################################ -->
<!--      muT ~ dnorm(80,.01)     # Mean of the true scores -->

<!--      tau.T ~ dgamma(1, 36)   # Precision of the true scores -->
<!--      tau.E ~ dgamma(1, 16)   # Precision of the errors -->

<!--      sigma.squared.T <- 1/tau.T    # Variance of the true scores -->
<!--      sigma.squared.E <- 1/tau.E    # Variance of the errors -->
<!--      # get SD for summarizing -->
<!--      sigmaT <- pow(sigma.squared.T, 0.5) -->
<!--      sigmaE <- pow(sigma.squared.E, 0.5) -->
<!--      ############################################ -->
<!--      # MODEL FOR TRUE SCORES AND OBSERVABLES -->
<!--      ############################################ -->

<!--      for (i in 1:N) { -->
<!--           T[i] ~ dnorm(muT, tau.T)     # Distribution of true scores -->
<!--           for(j in 1:J){ -->
<!--                X[i,j] ~ dnorm(T[i], tau.E)     # Distribution of observables -->
<!--           } -->
<!--      } -->

<!--      ############################################ -->
<!--      # RELIABILITY -->
<!--      ############################################ -->
<!--      rho <- sigma.squared.T/(sigma.squared.T+sigma.squared.E) -->
<!--      rhocomp <- J*rho/((J-1)*rho+1) -->

<!-- } -->
<!-- # data -->
<!-- mydata <- list( -->
<!--   N = 10, J = 5, -->
<!--   X = matrix( -->
<!--     c(80, 77, 80, 73, 73, -->
<!--       83, 79, 78, 78, 77, -->
<!--       85, 77, 88, 81, 80, -->
<!--       76, 76, 76, 78, 67, -->
<!--       70, 69, 73, 71, 77, -->
<!--       87, 89, 92, 91, 87, -->
<!--       76, 75, 79, 80, 75, -->
<!--       86, 75, 80, 80, 82, -->
<!--       84, 79, 79, 77, 82, -->
<!--       96, 85, 91, 87, 90), -->
<!--     ncol=5, nrow=10, byrow=T) -->
<!-- ) -->

<!-- # initial values -->
<!-- start_values <- list( -->
<!--   list("T"=c(60,85,80,95,74,69,91,82,87,78), -->
<!--        "muT"=80, "tau.E"=0.06, "tau.T"=0.023), -->
<!--   list("T"=c(63, 79, 74, 104, 80, 71, 95, 72, 80, 82), -->
<!--        "muT"=100, "tau.E"=0.09, "tau.T"=0.05), -->
<!--   list("T"=c(59, 86, 88, 89, 76, 65, 94, 72, 95, 84), -->
<!--        "muT"=70, "tau.E"=0.03, "tau.T"=0.001), -->
<!--   list("T"=c(60, 87, 90, 91, 77, 74, 95, 76, 83, 87), -->
<!--        "muT"=90, "tau.E"=0.01, "tau.T"=0.1) -->
<!-- ) -->

<!-- # vector of all parameters to save -->
<!-- param_save <- c("T","muT","sigmaT","sigmaE", "rho", "rhocomp") -->

<!-- # fit model -->
<!-- fit <- jags( -->
<!--   model.file=jags.model.ctt2, -->
<!--   data=mydata, -->
<!--   inits=start_values, -->
<!--   parameters.to.save = param_save, -->
<!--   n.iter=4000, -->
<!--   n.burnin = 1000, -->
<!--   n.chains = 4, -->
<!--   n.thin=1, -->
<!--   progress.bar = "none") -->

<!-- print(fit) -->

<!-- # extract posteriors for all chains -->
<!-- jags.mcmc <- as.mcmc(fit) -->

<!-- R2jags::traceplot(jags.mcmc) -->

<!-- # gelman-rubin-brook -->
<!-- gelman.plot(jags.mcmc) -->

<!-- # convert to single data.frame for density plot -->
<!-- a <- colnames(as.data.frame(jags.mcmc[[1]])) -->
<!-- plot.data <- data.frame(as.matrix(jags.mcmc, chains=T, iters = T)) -->
<!-- colnames(plot.data) <- c("chain", "iter", a) -->


<!-- plot_title <- ggtitle("Posterior distributions", -->
<!--                       "with medians and 80% intervals") -->
<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c(paste0("T[",1:10,"]"), "muT"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->

<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c("sigmaT", "sigmaE"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->

<!-- mcmc_areas( -->
<!--   plot.data, -->
<!--   pars = c("rho", "rhocomp"), -->
<!--   prob = 0.8) + -->
<!--   plot_title -->

<!-- # I prefer a posterior plot that includes prior and MLE -->
<!-- MLE <- c(rowMeans(mydata$X), mean(mydata$X)) -->

<!-- prior_mu <- function(x){dnorm(x, 80, 10)} -->
<!-- x.mu<- seq(50.1, 100, 0.1) -->
<!-- prior.mu <- data.frame(mu=x.mu, dens.mu = prior_mu(x.mu)) -->

<!-- prior_sigt <- function(x){dinvgamma(x, 1, 6)} -->
<!-- x.sigt<- seq(.1, 15, 0.1) -->
<!-- prior.sigt <- data.frame(sigt=x.sigt, dens.sigt = prior_sigt(x.sigt)) -->

<!-- prior_sige <- function(x){dinvgamma(x, 1, 4)} -->
<!-- x.sige<- seq(.1, 10, 0.1) -->
<!-- prior.sige <- data.frame(sige=x.sige, dens.sige = prior_sige(x.sige)) -->

<!-- prior_t <- function(x){ -->
<!--   mu <- rnorm(1, 80, 10) -->
<!--   sig <- rinvgamma(1, 1, 4) -->
<!--   rnorm(x, mu, sig) -->
<!-- } -->
<!-- x.t<- seq(50.1, 100, 0.1) -->
<!-- prior.t <- data.frame(tr=prior_t(10000)) -->
<!-- cols <- c("Posterior"="#0072B2", "Prior"="#E69F00", "MLE"= "black")#"#56B4E9", "#E69F00" "#CC79A7" -->

<!-- p1 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[1]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[1], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p2 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[5]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[5], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p3 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`T[10]`, color="Posterior"))+ -->
<!--   geom_density(data=prior.t,aes(x=tr,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[10], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p4 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`muT`, color="Posterior"))+ -->
<!--   geom_line(data=prior.mu,aes(x=mu,y=dens.mu,color="Prior"))+ -->
<!--   geom_vline(aes(xintercept=MLE[11], color="MLE"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p5 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`sigmaT`, color="Posterior"))+ -->
<!--   geom_line(data=prior.sigt,aes(x=sigt,y=dens.sigt,color="Prior"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p6 <- ggplot()+ -->
<!--   geom_density(data=plot.data, aes(x=`sigmaE`, color="Posterior"))+ -->
<!--   geom_line(data=prior.sige,aes(x=sige,y=dens.sige,color="Prior"))+ -->
<!--   scale_color_manual(values=cols, name=NULL)+ -->
<!--   theme_bw()+ -->
<!--   theme(panel.grid = element_blank()) -->

<!-- p1 + p2 + p3 + p4 + p5 + p6 + plot_layout(ncol=3, guides="collect") -->

<!-- ``` -->

